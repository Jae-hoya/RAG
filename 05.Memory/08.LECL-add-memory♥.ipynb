{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECL(대화내용) 기억하기: 메모리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "# MessagesPlaceholder 공간만 잡아준다. 비어져 있는 상태에서, 대화를 쭉 이어나가면 MessagesPlaceholder에 대화기록이 쌓이게 된다.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful chatbots\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 버퍼를 생성하고, 메세지를 반환 기능을 활성화.\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    " return_messages=True, memory_key=\"chat_history\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 딕셔너리로 변환한다. 여기서는 메모리가 비어져 있으므로, 빈 딕셔너리로 초기화한다.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RunnablePassthrough.assign`을 사용하여 `chat_history`변수에 `memory_load_memory_variables` 함수의 결과를 할당하고(매핑), 이 결과에서 `chat_history`키에 해당하는 값을 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runnable = RunnablePassthrough.assign( # assign은 input과 chat_history에 해당하는 key, value쌍을 반환해주는 것이다.\n",
    "#     chat_history=RunnableLambda(memory.load_memory_variables) # load_memory_variables 함수를 호출한것과 같다. 즉, 지금까지 쌓아온 함수를 호출을 하는것.\n",
    "#     # | itemgetter(\"chat_history\") # memory_key와 동일하게 입력한다.\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'chain_history': {'chat_history': []}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # input은 사용자의 질문, chat_history는 대화의 기록\n",
    "# runnable.invoke({\"input\":\"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnablePassthrough.assign( # assign은 input과 chat_history에 해당하는 key, value쌍을 반환해주는 것이다.\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) # load_memory_variables 함수를 호출한것과 같다. 즉, 지금까지 쌓아온 함수를 호출을 하는것.\n",
    "    | itemgetter(\"chat_history\") # memory_key와 동일하게 입력한다. itemgetter의 역할은 dictionary가 주어졌을때, 해당 value로 끄집어 내주는 역할을 하는것이다.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'chat_history': []}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input은 사용자의 질문, chat_history는 대화의 기록. key, value쌍이 아닌 list만 나오게 된다.\n",
    "runnable.invoke({\"input\":\"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`runnable`에 첫대화를 시작.\n",
    "- `input`: 사용자의 입력 대화가 전달\n",
    "- `chat_history`: 대화 기록이 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'chat_history': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\":\"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 재호님! 만나서 반갑습니다. 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"만나서 반갑습니다. 제 이름은 재호입니다.\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='만나서 반갑습니다. 제 이름은 테디입니다'),\n",
       "  AIMessage(content='안녕하세요, 재호님! 만나서 반갑습니다. 어떻게 도와드릴까요?')]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"human\": \"만나서 반갑습니다. 제 이름은 테디입니다\"}, {\"ai\": response.content}\n",
    ")\n",
    "\n",
    "# 저장된 대화기록을 출력\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='네, 당신의 이름은 테디입니다. 어떻게 도와드릴까요?' response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 69, 'total_tokens': 86}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None} id='run-17bdd99b-d1ce-44ac-a10a-7a663e2168c1-0' usage_metadata={'input_tokens': 69, 'output_tokens': 17, 'total_tokens': 86}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"제 이름이 무엇이었는지 기억하세요?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 커스텀 ConversationChain구성 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# llm과 prompt, memory만 있으면 된다.\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 대화형 프롬프트를 생성. 이 프롬프트는 시스템 메세지, 이전대화 내역, 그리고 사용자의 입력 포함\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        ('human', \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 대화 버퍼 메로리를 새성하고, 메세지 반환기능 활성화\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "\n",
    "# runnable = RunnablePassthrough.assign(\n",
    "#     chat_history=RunnableLambda(memory.load_memory_variables)\n",
    "#     | itemgetter(\"chat_history\")\n",
    "# )\n",
    "# chain = runnable | prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConversationChain(Runnable):\n",
    "    # llm, prompt, memory를 받아서 저장\n",
    "    def __init__(self, llm, prompt, memory, input_key=\"input\"):\n",
    "        \n",
    "        self.prompt = prompt\n",
    "        self.memory = memory\n",
    "        self.input_key = input_key\n",
    "        # 체인을 받아준다.\n",
    "        self.chain = (\n",
    "            RunnablePassthrough.assign(\n",
    "                chat_history=RunnableLambda(self.memory.load_memory_variables)\n",
    "                | itemgetter(memory.memory_key) # memory_key와 동일하게 입력\n",
    "            )\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "    # invoke라는 함수를 통해서, 유저의 질문을 받아서 chain에 invoke하고, 답변을 받은다음 메모리에 저장하는 기능\n",
    "    def invoke(self, query, config=None, **kwargs):\n",
    "        answer = self.chain.invoke({self.input_key:query})\n",
    "        self.memory.save_context(inputs={\"human\": query}, outputs={'ai': answer})\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = MyConversationChain(llm, prompt, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 재호님! 반갑습니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"안녕하세여? 반갑습니다 제 이름은 재호입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'재호님이라고 하셨습니다! 맞나요?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"제 이름이 뭐라고요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, I can respond in English from now on! How can I assist you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"앞으로는 영어로만 답해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Jae-ho.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke(\"제 이름을다시한번 말해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='안녕하세여? 반갑습니다 제 이름은 재호입니다.'),\n",
       "  AIMessage(content='안녕하세요, 재호님! 반갑습니다. 어떻게 도와드릴까요?'),\n",
       "  HumanMessage(content='제 이름이 뭐라고요?'),\n",
       "  AIMessage(content='재호님이라고 하셨습니다! 맞나요?'),\n",
       "  HumanMessage(content='앞으로는 영어로만 답해주세요'),\n",
       "  AIMessage(content='Sure, I can respond in English from now on! How can I assist you today?'),\n",
       "  HumanMessage(content='제 이름을다시한번 말해주세요'),\n",
       "  AIMessage(content='Your name is Jae-ho.')]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "conversation_chain.memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세여? 반갑습니다 제 이름은 재호입니다.'),\n",
       " AIMessage(content='안녕하세요, 재호님! 반갑습니다. 어떻게 도와드릴까요?'),\n",
       " HumanMessage(content='제 이름이 뭐라고요?'),\n",
       " AIMessage(content='재호님이라고 하셨습니다. 맞나요?'),\n",
       " HumanMessage(content='앞으로는 영어로만 답해주세요'),\n",
       " AIMessage(content='Sure, I can respond in English from now on. How can I assist you today?'),\n",
       " HumanMessage(content='제 이름을다시한번 말해주세요'),\n",
       " AIMessage(content='Your name is Jaeho.')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.memory.load_memory_variables({})[\"chat_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-mcYdBRZz-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
