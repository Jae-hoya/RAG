{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이전 대화를 기억하는 Chain 생성방법\n",
    "\n",
    "in_memory를 가볍게 사용하는 방법이다. \n",
    "\n",
    "Runnable history를 사용하는, 영구적인 저장 방법이 아닌, 임시적인 저장방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH05-Memory\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH05-Memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이전 대화 내용을 기억하는 multi-turn Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "# from langchain_core.chat_history import BaseChatMessageHistory\n",
    "# from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system', \n",
    "            \"당신은 Question-Answering Chatbot입니다. 주어진 질문에 대하여 답변을 제공해 주세요.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history'), # 대화내용이 쌓이는 곳.\n",
    "        (\n",
    "            'human',\n",
    "            '#Question:\\n{question}'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "# prompt의 변수는 question과 chat_history 2개다.\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화를 기록하는 체인 `chain_with_history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션을 저장하는 딕셔너리\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_ids):\n",
    "    print(f\"[대화 세션ID]: {session_ids}\")\n",
    "    if session_ids not in store:\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt의 question과 chat_history 확인\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history, # 세션 기록을 가져오는 함수\n",
    "    input_messages_key=\"question\", # 사용자의 질문이 템플릿 변수에 들어갈 key\n",
    "    history_messages_key=\"chat_history\" # 기록 메세지의 키\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 재호님! 만나서 반갑습니다. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    {\"question\": \"나의 이름은 재호입니다.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'재호님이라고 하셨습니다!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    {\"question\": \"내 이름이 뭐라고??\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 당신의 이름을 알 수 있는 정보가 없습니다. 당신의 이름을 알려주시면 좋겠습니다!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    {\"question\": \"내 이름이 뭐라고??\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc1234\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-mcYdBRZz-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
