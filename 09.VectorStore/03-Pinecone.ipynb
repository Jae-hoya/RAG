{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone\n",
    "Pinecone은 고성능 벡터 데이터베이스로, AI 및 머신러닝 애플리케이션을 위한 효율적인 벡터 저장 및 검색 솔루션입니다.\n",
    "\n",
    "Pinecone, Chroma, Faiss와 같은 벡터 데이터베이스들을 비교해보겠습니다.\n",
    "\n",
    "**Pinecone의 장점**\n",
    "\n",
    "1. 확장성: **대규모 데이터셋**에 대해 뛰어난 확장성을 제공합니다.\n",
    "\n",
    "2. 관리 용이성: 완전 관리형 서비스로, 인프라 관리 부담이 적습니다.\n",
    "\n",
    "3. 실시간 업데이트: 데이터의 실시간 삽입, 업데이트, 삭제가 가능합니다.\n",
    "\n",
    "4. 고가용성: 클라우드 기반으로 높은 가용성과 내구성을 제공합니다.\n",
    "\n",
    "5. API 친화적: RESTful/Python API를 통해 쉽게 통합할 수 있습니다.\n",
    "\n",
    "**Pinecone의 단점**\n",
    "\n",
    "1. 비용: Chroma나 Faiss에 비해 상대적으로 비용이 높을 수 있습니다.\n",
    "\n",
    "2. 커스터마이징 제한: 완전 관리형 서비스이기 때문에 세부적인 커스터마이징에 제한이 있을 수 있습니다.\n",
    "\n",
    "3. 데이터 위치: 클라우드에 데이터를 저장해야 하므로, 데이터 주권 문제가 있을 수 있습니다.\n",
    "\n",
    "Chroma나 Faiss와 비교했을 때:\n",
    "\n",
    "- Chroma/FAISS 오픈소스이며 로컬에서 실행 가능하여 초기 비용이 낮고 데이터 제어가 용이합니다. 커스터마이징의 자유도가 높습니다. 하지만 대규모 확장성 면에서는 Pinecone에 비해 제한적일 수 있습니다.\n",
    "- 선택은 프로젝트의 규모, 요구사항, 예산 등을 고려하여 결정해야 합니다. 대규모 프로덕션 환경에서는 Pinecone이 유리할 수 있지만, 소규모 프로젝트나 실험적인 환경에서는 Chroma나 Faiss가 더 적합할 수 있습니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [Pinecone 공식 홈페이지](https://docs.pinecone.io/integrations/langchain)\n",
    "- [Pinecone 랭체인](https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 불용어 사전 \n",
    "한글 불용어 사전 불러오기 (불용어 사전 출처: https://www.ranks.nl/stopwords/korean)\n",
    "\n",
    "불용어는 큰 의미를 갖지 않는것을 의미한다. 이 불용어를 제거하고 retriever하게끔 만들어 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아',\n",
       " '휴',\n",
       " '아이구',\n",
       " '아이쿠',\n",
       " '아이고',\n",
       " '어',\n",
       " '나',\n",
       " '우리',\n",
       " '저희',\n",
       " '따라',\n",
       " '의해',\n",
       " '을',\n",
       " '를',\n",
       " '에',\n",
       " '의',\n",
       " '가',\n",
       " '으로',\n",
       " '로',\n",
       " '에게',\n",
       " '뿐이다',\n",
       " '의거하여',\n",
       " '근거하여',\n",
       " '입각하여',\n",
       " '기준으로',\n",
       " '예하면',\n",
       " '예를 들면',\n",
       " '예를 들자면',\n",
       " '저',\n",
       " '소인',\n",
       " '소생',\n",
       " '저희',\n",
       " '지말고',\n",
       " '하지마',\n",
       " '하지마라',\n",
       " '다른',\n",
       " '물론',\n",
       " '또한',\n",
       " '그리고',\n",
       " '비길수 없다',\n",
       " '해서는 안된다',\n",
       " '뿐만 아니라',\n",
       " '만이 아니다',\n",
       " '만은 아니다',\n",
       " '막론하고',\n",
       " '관계없이',\n",
       " '그치지 않다',\n",
       " '그러나',\n",
       " '그런데',\n",
       " '하지만',\n",
       " '든간에',\n",
       " '논하지 않다',\n",
       " '따지지 않다',\n",
       " '설사',\n",
       " '비록',\n",
       " '더라도',\n",
       " '아니면',\n",
       " '만 못하다',\n",
       " '하는 편이 낫다',\n",
       " '불문하고',\n",
       " '향하여',\n",
       " '향해서',\n",
       " '향하다',\n",
       " '쪽으로',\n",
       " '틈타',\n",
       " '이용하여',\n",
       " '타다',\n",
       " '오르다',\n",
       " '제외하고',\n",
       " '이 외에',\n",
       " '이 밖에',\n",
       " '하여야',\n",
       " '비로소',\n",
       " '한다면 몰라도',\n",
       " '외에도',\n",
       " '이곳',\n",
       " '여기',\n",
       " '부터',\n",
       " '기점으로',\n",
       " '따라서',\n",
       " '할 생각이다',\n",
       " '하려고하다',\n",
       " '이리하여',\n",
       " '그리하여',\n",
       " '그렇게 함으로써',\n",
       " '하지만',\n",
       " '일때',\n",
       " '할때',\n",
       " '앞에서',\n",
       " '중에서',\n",
       " '보는데서',\n",
       " '으로써',\n",
       " '로써',\n",
       " '까지',\n",
       " '해야한다',\n",
       " '일것이다',\n",
       " '반드시',\n",
       " '할줄알다',\n",
       " '할수있다',\n",
       " '할수있어',\n",
       " '임에 틀림없다',\n",
       " '한다면',\n",
       " '등',\n",
       " '등등',\n",
       " '제',\n",
       " '겨우',\n",
       " '단지',\n",
       " '다만',\n",
       " '할뿐',\n",
       " '딩동',\n",
       " '댕그',\n",
       " '대해서',\n",
       " '대하여',\n",
       " '대하면',\n",
       " '훨씬',\n",
       " '얼마나',\n",
       " '얼마만큼',\n",
       " '얼마큼',\n",
       " '남짓',\n",
       " '여',\n",
       " '얼마간',\n",
       " '약간',\n",
       " '다소',\n",
       " '좀',\n",
       " '조금',\n",
       " '다수',\n",
       " '몇',\n",
       " '얼마',\n",
       " '지만',\n",
       " '하물며',\n",
       " '또한',\n",
       " '그러나',\n",
       " '그렇지만',\n",
       " '하지만',\n",
       " '이외에도',\n",
       " '대해 말하자면',\n",
       " '뿐이다',\n",
       " '다음에',\n",
       " '반대로',\n",
       " '반대로 말하자면',\n",
       " '이와 반대로',\n",
       " '바꾸어서 말하면',\n",
       " '바꾸어서 한다면',\n",
       " '만약',\n",
       " '그렇지않으면',\n",
       " '까악',\n",
       " '툭',\n",
       " '딱',\n",
       " '삐걱거리다',\n",
       " '보드득',\n",
       " '비걱거리다',\n",
       " '꽈당',\n",
       " '응당',\n",
       " '해야한다',\n",
       " '에 가서',\n",
       " '각',\n",
       " '각각',\n",
       " '여러분',\n",
       " '각종',\n",
       " '각자',\n",
       " '제각기',\n",
       " '하도록하다',\n",
       " '와',\n",
       " '과',\n",
       " '그러므로',\n",
       " '그래서',\n",
       " '고로',\n",
       " '한 까닭에',\n",
       " '하기 때문에',\n",
       " '거니와',\n",
       " '이지만',\n",
       " '대하여',\n",
       " '관하여',\n",
       " '관한',\n",
       " '과연',\n",
       " '실로',\n",
       " '아니나다를가',\n",
       " '생각한대로',\n",
       " '진짜로',\n",
       " '한적이있다',\n",
       " '하곤하였다',\n",
       " '하',\n",
       " '하하',\n",
       " '허허',\n",
       " '아하',\n",
       " '거바',\n",
       " '와',\n",
       " '오',\n",
       " '왜',\n",
       " '어째서',\n",
       " '무엇때문에',\n",
       " '어찌',\n",
       " '하겠는가',\n",
       " '무슨',\n",
       " '어디',\n",
       " '어느곳',\n",
       " '더군다나',\n",
       " '하물며',\n",
       " '더욱이는',\n",
       " '어느때',\n",
       " '언제',\n",
       " '야',\n",
       " '이봐',\n",
       " '어이',\n",
       " '여보시오',\n",
       " '흐흐',\n",
       " '흥',\n",
       " '휴',\n",
       " '헉헉',\n",
       " '헐떡헐떡',\n",
       " '영차',\n",
       " '여차',\n",
       " '어기여차',\n",
       " '끙끙',\n",
       " '아야',\n",
       " '앗',\n",
       " '아야',\n",
       " '콸콸',\n",
       " '졸졸',\n",
       " '좍좍',\n",
       " '뚝뚝',\n",
       " '주룩주룩',\n",
       " '솨',\n",
       " '우르르',\n",
       " '그래도',\n",
       " '또',\n",
       " '그리고',\n",
       " '바꾸어말하면',\n",
       " '바꾸어말하자면',\n",
       " '혹은',\n",
       " '혹시',\n",
       " '답다',\n",
       " '및',\n",
       " '그에 따르는',\n",
       " '때가 되어',\n",
       " '즉',\n",
       " '지든지',\n",
       " '설령',\n",
       " '가령',\n",
       " '하더라도',\n",
       " '할지라도',\n",
       " '일지라도',\n",
       " '지든지',\n",
       " '몇',\n",
       " '거의',\n",
       " '하마터면',\n",
       " '인젠',\n",
       " '이젠',\n",
       " '된바에야',\n",
       " '된이상',\n",
       " '만큼\\t어찌됏든',\n",
       " '그위에',\n",
       " '게다가',\n",
       " '점에서 보아',\n",
       " '비추어 보아',\n",
       " '고려하면',\n",
       " '하게될것이다',\n",
       " '일것이다',\n",
       " '비교적',\n",
       " '좀',\n",
       " '보다더',\n",
       " '비하면',\n",
       " '시키다',\n",
       " '하게하다',\n",
       " '할만하다',\n",
       " '의해서',\n",
       " '연이서',\n",
       " '이어서',\n",
       " '잇따라',\n",
       " '뒤따라',\n",
       " '뒤이어',\n",
       " '결국',\n",
       " '의지하여',\n",
       " '기대여',\n",
       " '통하여',\n",
       " '자마자',\n",
       " '더욱더',\n",
       " '불구하고',\n",
       " '얼마든지',\n",
       " '마음대로',\n",
       " '주저하지 않고',\n",
       " '곧',\n",
       " '즉시',\n",
       " '바로',\n",
       " '당장',\n",
       " '하자마자',\n",
       " '밖에 안된다',\n",
       " '하면된다',\n",
       " '그래',\n",
       " '그렇지',\n",
       " '요컨대',\n",
       " '다시 말하자면',\n",
       " '바꿔 말하면',\n",
       " '즉',\n",
       " '구체적으로',\n",
       " '말하자면',\n",
       " '시작하여',\n",
       " '시초에',\n",
       " '이상',\n",
       " '허',\n",
       " '헉',\n",
       " '허걱',\n",
       " '바와같이',\n",
       " '해도좋다',\n",
       " '해도된다',\n",
       " '게다가',\n",
       " '더구나',\n",
       " '하물며',\n",
       " '와르르',\n",
       " '팍',\n",
       " '퍽',\n",
       " '펄렁',\n",
       " '동안',\n",
       " '이래',\n",
       " '하고있었다',\n",
       " '이었다',\n",
       " '에서',\n",
       " '로부터',\n",
       " '까지',\n",
       " '예하면',\n",
       " '했어요',\n",
       " '해요',\n",
       " '함께',\n",
       " '같이',\n",
       " '더불어',\n",
       " '마저',\n",
       " '마저도',\n",
       " '양자',\n",
       " '모두',\n",
       " '습니다',\n",
       " '가까스로',\n",
       " '하려고하다',\n",
       " '즈음하여',\n",
       " '다른',\n",
       " '다른 방면으로',\n",
       " '해봐요',\n",
       " '습니까',\n",
       " '했어요',\n",
       " '말할것도 없고',\n",
       " '무릎쓰고',\n",
       " '개의치않고',\n",
       " '하는것만 못하다',\n",
       " '하는것이 낫다',\n",
       " '매',\n",
       " '매번',\n",
       " '들',\n",
       " '모',\n",
       " '어느것',\n",
       " '어느',\n",
       " '로써',\n",
       " '갖고말하자면',\n",
       " '어디',\n",
       " '어느쪽',\n",
       " '어느것',\n",
       " '어느해',\n",
       " '어느 년도',\n",
       " '라 해도',\n",
       " '언젠가',\n",
       " '어떤것',\n",
       " '어느것',\n",
       " '저기',\n",
       " '저쪽',\n",
       " '저것',\n",
       " '그때',\n",
       " '그럼',\n",
       " '그러면',\n",
       " '요만한걸',\n",
       " '그래',\n",
       " '그때',\n",
       " '저것만큼',\n",
       " '그저',\n",
       " '이르기까지',\n",
       " '할 줄 안다',\n",
       " '할 힘이 있다',\n",
       " '너',\n",
       " '너희',\n",
       " '당신',\n",
       " '어찌',\n",
       " '설마',\n",
       " '차라리',\n",
       " '할지언정',\n",
       " '할지라도',\n",
       " '할망정',\n",
       " '할지언정',\n",
       " '구토하다',\n",
       " '게우다',\n",
       " '토하다',\n",
       " '메쓰겁다',\n",
       " '옆사람',\n",
       " '퉤',\n",
       " '쳇',\n",
       " '의거하여',\n",
       " '근거하여',\n",
       " '의해',\n",
       " '따라',\n",
       " '힘입어',\n",
       " '그',\n",
       " '다음',\n",
       " '버금',\n",
       " '두번째로',\n",
       " '기타',\n",
       " '첫번째로',\n",
       " '나머지는',\n",
       " '그중에서',\n",
       " '견지에서',\n",
       " '형식으로 쓰여',\n",
       " '입장에서',\n",
       " '위해서',\n",
       " '단지',\n",
       " '의해되다',\n",
       " '하도록시키다',\n",
       " '뿐만아니라',\n",
       " '반대로',\n",
       " '전후',\n",
       " '전자',\n",
       " '앞의것',\n",
       " '잠시',\n",
       " '잠깐',\n",
       " '하면서',\n",
       " '그렇지만',\n",
       " '다음에',\n",
       " '그러한즉',\n",
       " '그런즉',\n",
       " '남들',\n",
       " '아무거나',\n",
       " '어찌하든지',\n",
       " '같다',\n",
       " '비슷하다',\n",
       " '예컨대',\n",
       " '이럴정도로',\n",
       " '어떻게',\n",
       " '만약',\n",
       " '만일',\n",
       " '위에서 서술한바와같이',\n",
       " '인 듯하다',\n",
       " '하지 않는다면',\n",
       " '만약에',\n",
       " '무엇',\n",
       " '무슨',\n",
       " '어느',\n",
       " '어떤',\n",
       " '아래윗',\n",
       " '조차',\n",
       " '한데',\n",
       " '그럼에도 불구하고',\n",
       " '여전히',\n",
       " '심지어',\n",
       " '까지도',\n",
       " '조차도',\n",
       " '하지 않도록',\n",
       " '않기 위하여',\n",
       " '때',\n",
       " '시각',\n",
       " '무렵',\n",
       " '시간',\n",
       " '동안',\n",
       " '어때',\n",
       " '어떠한',\n",
       " '하여금',\n",
       " '네',\n",
       " '예',\n",
       " '우선',\n",
       " '누구',\n",
       " '누가 알겠는가',\n",
       " '아무도',\n",
       " '줄은모른다',\n",
       " '줄은 몰랏다',\n",
       " '하는 김에',\n",
       " '겸사겸사',\n",
       " '하는바',\n",
       " '그런 까닭에',\n",
       " '한 이유는',\n",
       " '그러니',\n",
       " '그러니까',\n",
       " '때문에',\n",
       " '그',\n",
       " '너희',\n",
       " '그들',\n",
       " '너희들',\n",
       " '타인',\n",
       " '것',\n",
       " '것들',\n",
       " '너',\n",
       " '위하여',\n",
       " '공동으로',\n",
       " '동시에',\n",
       " '하기 위하여',\n",
       " '어찌하여',\n",
       " '무엇때문에',\n",
       " '붕붕',\n",
       " '윙윙',\n",
       " '나',\n",
       " '우리',\n",
       " '엉엉',\n",
       " '휘익',\n",
       " '윙윙',\n",
       " '오호',\n",
       " '아하',\n",
       " '어쨋든',\n",
       " '만 못하다\\t하기보다는',\n",
       " '차라리',\n",
       " '하는 편이 낫다',\n",
       " '흐흐',\n",
       " '놀라다',\n",
       " '상대적으로 말하자면',\n",
       " '마치',\n",
       " '아니라면',\n",
       " '쉿',\n",
       " '그렇지 않으면',\n",
       " '그렇지 않다면',\n",
       " '안 그러면',\n",
       " '아니었다면',\n",
       " '하든지',\n",
       " '아니면',\n",
       " '이라면',\n",
       " '좋아',\n",
       " '알았어',\n",
       " '하는것도',\n",
       " '그만이다',\n",
       " '어쩔수 없다',\n",
       " '하나',\n",
       " '일',\n",
       " '일반적으로',\n",
       " '일단',\n",
       " '한켠으로는',\n",
       " '오자마자',\n",
       " '이렇게되면',\n",
       " '이와같다면',\n",
       " '전부',\n",
       " '한마디',\n",
       " '한항목',\n",
       " '근거로',\n",
       " '하기에',\n",
       " '아울러',\n",
       " '하지 않도록',\n",
       " '않기 위해서',\n",
       " '이르기까지',\n",
       " '이 되다',\n",
       " '로 인하여',\n",
       " '까닭으로',\n",
       " '이유만으로',\n",
       " '이로 인하여',\n",
       " '그래서',\n",
       " '이 때문에',\n",
       " '그러므로',\n",
       " '그런 까닭에',\n",
       " '알 수 있다',\n",
       " '결론을 낼 수 있다',\n",
       " '으로 인하여',\n",
       " '있다',\n",
       " '어떤것',\n",
       " '관계가 있다',\n",
       " '관련이 있다',\n",
       " '연관되다',\n",
       " '어떤것들',\n",
       " '에 대해',\n",
       " '이리하여',\n",
       " '그리하여',\n",
       " '여부',\n",
       " '하기보다는',\n",
       " '하느니',\n",
       " '하면 할수록',\n",
       " '운운',\n",
       " '이러이러하다',\n",
       " '하구나',\n",
       " '하도다',\n",
       " '다시말하면',\n",
       " '다음으로',\n",
       " '에 있다',\n",
       " '에 달려 있다',\n",
       " '우리',\n",
       " '우리들',\n",
       " '오히려',\n",
       " '하기는한데',\n",
       " '어떻게',\n",
       " '어떻해',\n",
       " '어찌됏어',\n",
       " '어때',\n",
       " '어째서',\n",
       " '본대로',\n",
       " '자',\n",
       " '이',\n",
       " '이쪽',\n",
       " '여기',\n",
       " '이것',\n",
       " '이번',\n",
       " '이렇게말하자면',\n",
       " '이런',\n",
       " '이러한',\n",
       " '이와 같은',\n",
       " '요만큼',\n",
       " '요만한 것',\n",
       " '얼마 안 되는 것',\n",
       " '이만큼',\n",
       " '이 정도의',\n",
       " '이렇게 많은 것',\n",
       " '이와 같다',\n",
       " '이때',\n",
       " '이렇구나',\n",
       " '것과 같이',\n",
       " '끼익',\n",
       " '삐걱',\n",
       " '따위',\n",
       " '와 같은 사람들',\n",
       " '부류의 사람들',\n",
       " '왜냐하면',\n",
       " '중의하나',\n",
       " '오직',\n",
       " '오로지',\n",
       " '에 한하다',\n",
       " '하기만 하면',\n",
       " '도착하다',\n",
       " '까지 미치다',\n",
       " '도달하다',\n",
       " '정도에 이르다',\n",
       " '할 지경이다',\n",
       " '결과에 이르다',\n",
       " '관해서는',\n",
       " '여러분',\n",
       " '하고 있다',\n",
       " '한 후',\n",
       " '혼자',\n",
       " '자기',\n",
       " '자기집',\n",
       " '자신',\n",
       " '우에 종합한것과같이',\n",
       " '총적으로 보면',\n",
       " '총적으로 말하면',\n",
       " '총적으로',\n",
       " '대로 하다',\n",
       " '으로서',\n",
       " '참',\n",
       " '그만이다',\n",
       " '할 따름이다',\n",
       " '쿵',\n",
       " '탕탕',\n",
       " '쾅쾅',\n",
       " '둥둥',\n",
       " '봐',\n",
       " '봐라',\n",
       " '아이야',\n",
       " '아니',\n",
       " '와아',\n",
       " '응',\n",
       " '아이',\n",
       " '참나',\n",
       " '년',\n",
       " '월',\n",
       " '일',\n",
       " '령',\n",
       " '영',\n",
       " '일',\n",
       " '이',\n",
       " '삼',\n",
       " '사',\n",
       " '오',\n",
       " '육',\n",
       " '륙',\n",
       " '칠',\n",
       " '팔',\n",
       " '구',\n",
       " '이천육',\n",
       " '이천칠',\n",
       " '이천팔',\n",
       " '이천구',\n",
       " '하나',\n",
       " '둘',\n",
       " '셋',\n",
       " '넷',\n",
       " '다섯',\n",
       " '여섯',\n",
       " '일곱',\n",
       " '여덟',\n",
       " '아홉',\n",
       " '령',\n",
       " '영']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.korean import stopwords\n",
    "\n",
    "stopword = stopwords()\n",
    "stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 추가\n",
    "stopword.append(\"를\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import glob\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "split_docs = []\n",
    "\n",
    "# 텍스트 파일을 load -> List[Document] 형태로 변환\n",
    "files = sorted(glob.glob(\"data/*.pdf\"))\n",
    "for file in files:\n",
    "    loader = PDFPlumberLoader(file)\n",
    "    split_docs.extend(loader.load_and_split(text_splitter))\n",
    "\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARAGOG: Advanced RAG Output Grading\\nMatouˇs Eibich Shivay Nagpal Alexander Fred-Ojala\\nPredli Predli Predli & UC Berkeley\\nmatous@predli.com shivay@predli.com afo@berkeley.edu\\nApril 2, 2024\\nAbstract\\nRetrieval-Augmented Generation (RAG) is essential for integrating external knowledge into\\nLarge Language Model (LLM) outputs. While the literature on RAG is growing, it primarily\\nfocusesonsystematicreviewsandcomparisonsofnewstate-of-the-art(SoTA)techniquesagainst\\ntheirpredecessors,withagapinextensiveexperimentalcomparisons. Thisstudybeginstoaddress\\nthisgapbyassessingvariousRAGmethods’impactsonretrievalprecisionandanswersimilarity.\\nWefoundthatHypotheticalDocumentEmbedding(HyDE)andLLMrerankingsignificantlyen-\\nhance retrieval precision. However, Maximal Marginal Relevance (MMR) and Cohere rerank did\\nnot exhibit notable advantages over a baseline Naive RAG system, and Multi-query approaches\\nunderperformed. SentenceWindowRetrievalemergedasthemosteffectiveforretrievalprecision,'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\ARAGOG_Advanced RAG Output Grading.pdf',\n",
       " 'file_path': 'data\\\\ARAGOG_Advanced RAG Output Grading.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 14,\n",
       " 'Author': '',\n",
       " 'CreationDate': 'D:20240402041602Z',\n",
       " 'Creator': 'LaTeX with hyperref',\n",
       " 'Keywords': '',\n",
       " 'ModDate': 'D:20240402041602Z',\n",
       " 'PTEX.Fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'Producer': 'pdfTeX-1.40.25',\n",
       " 'Subject': '',\n",
       " 'Title': '',\n",
       " 'Trapped': 'False'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서의 전처리\n",
    "- 필요한 `metadata` 정보를 추출합니다.\n",
    "\n",
    "- 최소 길이 이상의 데이만 필터링 합니다.\n",
    "\n",
    "- 문서의 `basename` 을 사용할지 여부를 지정합니다. 기본값은 False 입니다.\n",
    "\n",
    "    - 여기서 `basename` 이란 파일 경로의 가장 마지막 부분을 의미합니다.\n",
    "    - 예를 들어, `/Users/teddy/data/document.pdf` 의 경우 `document.pdf` 가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARAGOG: Advanced RAG Output Grading\\nMatouˇs Eibich Shivay Nagpal Alexander Fred-Ojala\\nPredli Predli Predli & UC Berkeley\\nmatous@predli.com shivay@predli.com afo@berkeley.edu\\nApril 2, 2024\\nAbstract\\nRetrieval-Augmented Generation (RAG) is essential for integrating external knowledge into\\nLarge Language Model (LLM) outputs. While the literature on RAG is growing, it primarily\\nfocusesonsystematicreviewsandcomparisonsofnewstate-of-the-art(SoTA)techniquesagainst\\ntheirpredecessors,withagapinextensiveexperimentalcomparisons. Thisstudybeginstoaddress\\nthisgapbyassessingvariousRAGmethods’impactsonretrievalprecisionandanswersimilarity.\\nWefoundthatHypotheticalDocumentEmbedding(HyDE)andLLMrerankingsignificantlyen-\\nhance retrieval precision. However, Maximal Marginal Relevance (MMR) and Cohere rerank did\\nnot exhibit notable advantages over a baseline Naive RAG system, and Multi-query approaches\\nunderperformed. SentenceWindowRetrievalemergedasthemosteffectiveforretrievalprecision,'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\ARAGOG_Advanced RAG Output Grading.pdf',\n",
       " 'file_path': 'data\\\\ARAGOG_Advanced RAG Output Grading.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 14,\n",
       " 'Author': '',\n",
       " 'CreationDate': 'D:20240402041602Z',\n",
       " 'Creator': 'LaTeX with hyperref',\n",
       " 'Keywords': '',\n",
       " 'ModDate': 'D:20240402041602Z',\n",
       " 'PTEX.Fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'Producer': 'pdfTeX-1.40.25',\n",
       " 'Subject': '',\n",
       " 'Title': '',\n",
       " 'Trapped': 'False'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7183f29d5e49c6bdb2b12b70a2ef04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 저장하고 싶은 메타데이터만 뽑는다.\n",
    "from langchain_teddynote.community.pinecone import preprocess_documents\n",
    "\n",
    "contents, metadatas = preprocess_documents(\n",
    "    split_docs=split_docs,\n",
    "    #metadata_keys=[\"source\", \"page\", \"author\"],\n",
    "    metadata_keys=[\"source\", \"page\"],\n",
    "    min_length=20, #문서의 길이를 가지고 filtering. 5글자 이상의 문서만을 사용. (예를들어 숫자만 있거나 제목만 있는경우) 줄어든것을 확인할 수 있다.\n",
    "    use_basename=True # False인 경우 폴더 위치까지 모두 적혀있다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARAGOG: Advanced RAG Output Grading\\nMatouˇs Eibich Shivay Nagpal Alexander Fred-Ojala\\nPredli Predli Predli & UC Berkeley\\nmatous@predli.com shivay@predli.com afo@berkeley.edu\\nApril 2, 2024\\nAbstract\\nRetrieval-Augmented Generation (RAG) is essential for integrating external knowledge into\\nLarge Language Model (LLM) outputs. While the literature on RAG is growing, it primarily\\nfocusesonsystematicreviewsandcomparisonsofnewstate-of-the-art(SoTA)techniquesagainst\\ntheirpredecessors,withagapinextensiveexperimentalcomparisons. Thisstudybeginstoaddress\\nthisgapbyassessingvariousRAGmethods’impactsonretrievalprecisionandanswersimilarity.\\nWefoundthatHypotheticalDocumentEmbedding(HyDE)andLLMrerankingsignificantlyen-\\nhance retrieval precision. However, Maximal Marginal Relevance (MMR) and Cohere rerank did\\nnot exhibit notable advantages over a baseline Naive RAG system, and Multi-query approaches\\nunderperformed. SentenceWindowRetrievalemergedasthemosteffectiveforretrievalprecision,',\n",
       " 'despite its variable performance on answer similarity. The study confirms the potential of the\\nDocument Summary Index as a competent retrieval approach. All resources related to this re-\\nsearcharepubliclyaccessibleforfurtherinvestigationthroughourGitHubrepositoryARAGOG.\\nWe welcome the community to further this exploratory study in RAG systems.\\n1 Introduction\\nLarge Language Models (LLMs) have significantly advanced the field of natural language processing,\\nenabling a wide range of applications from text generation to question answering. However, inte-\\ngrating dynamic, external information remains a challenge for these models. Retrieval Augmented\\nGeneration(RAG)techniquesaddressthislimitationbyincorporatingexternalknowledgesourcesinto\\nthe generation process, thus enhancing the models’ ability to produce contextually relevant and in-\\nformedoutputs. Thisintegrationofretrievalmechanismswithgenerativemodelsisakeydevelopment',\n",
       " 'in improving the performance and versatility of LLMs, facilitating more accurate and context-aware\\nresponses. See Figure 1 for an overview of the standard RAG workflow.\\nDespite the growing interest in RAG techniques within the domain of LLMs, the existing body of\\nliterature primarily consists of systematic reviews (Gao et al., 2024) and direct comparisons between\\nsuccessive state-of-the-art (SoTA) models (Gao et al., 2022; Jiang et al., 2023). This pattern reveals\\na notable gap: a comprehensive experimental comparison across a broad spectrum of advanced RAG\\ntechniques is missing. Such a comparison is crucial for understanding the relative strengths and\\nweaknessesofthesetechniquesinenhancingLLMs’performanceacrossvarioustasks. Thisstudyseeks\\nto contribute to bridging this gap by providing an extensive evaluation of multiple RAG techniques\\nand their combinations, thereby offering insights into their efficacy and applicability in real-world\\nscenarios.',\n",
       " 'scenarios.\\nThefocusofthisinvestigationisaspectrumofadvancedRAGtechniquesaimedatoptimizingthe\\nretrieval process. These techniques can be categorized into several areas:\\n1\\n4202\\nrpA\\n1\\n]LC.sc[\\n1v73010.4042:viXra',\n",
       " 'RAG Technique Type\\nSentence-window retrieval\\nDecoupling of Retrieval and Generation\\nDocument summary index\\nHyDE\\nQuery Expansion\\nMulti-query\\nMaximal Marginal Relevance (MMR) Enhancement Mechanism\\nCohere Re-ranker\\nRe-rankers\\nLLM-based Re-ranker\\nToevaluatetheRAGtechniques,thisstudyleveragestwometrics: RetrievalPrecisionandAnswer\\nSimilarity(TonicAI,2023). RetrievalPrecisionmeasurestherelevanceoftheretrievedcontexttothe\\nquestionasked,whileAnswerSimilarityassesseshowcloselythesystem’sanswersalignwithreference\\nresponses, on a scale from 0 to 5.\\nFigure 1: A high-level overview of the workflow within a Retrieval-Augmented Generation (RAG) system. This\\nprocessdiagramshowshowauserqueryisprocessedbythesystemtoretrieverelevantdocumentsfromadatabase\\nandhowthesedocumentsinformthegenerationofaresponse.\\n2 RAG Techniques\\n2.1 Sentence-window retrieval\\nThe Sentence-window Retrieval technique is grounded in the principle of optimizing both retrieval']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'page'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatas.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARAGOG_Advanced RAG Output Grading.pdf',\n",
       " 'ARAGOG_Advanced RAG Output Grading.pdf',\n",
       " 'ARAGOG_Advanced RAG Output Grading.pdf',\n",
       " 'ARAGOG_Advanced RAG Output Grading.pdf',\n",
       " 'ARAGOG_Advanced RAG Output Grading.pdf']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatas[\"source\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 617, 617)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내용 3개가 맞아 떨어지는지 확인\n",
    "len(contents), len(metadatas[\"source\"]), len(metadatas['page'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로운 VectorStore 인덱스 생성\n",
    "Pinecone 의 새로운 인덱스를 생성합니다.\n",
    "\n",
    "pinecone 인덱스를 생성합니다.\n",
    "\n",
    "**주의사항**\n",
    "\n",
    "- metric 은 유사도 측정 방법을 지정합니다. 만약 HybridSearch 를 고려하고 있다면 metric 은 dotproduct 로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[create_index]\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'jaehonote-namespace': {'vector_count': 0}},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_teddynote.community.pinecone import create_index\n",
    "\n",
    "pc_index = create_index(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    index_name=\"jaeho-note-index\", # 인덱스 이름을 지정합니다.\n",
    "    dimension=1536, # Embedding 차원과 맞춥니다. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "    metric=\"dotproduct\" # 유사도 측정 방법을 지정합니다. (dotproduct, euclidean, cosine) Hybrid search를 위해선 dotproduct를 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래는 유료 Pod 를 사용하는 예시입니다. 유료 Pod 는 무료 Serverless Pod 대비 더 확장된 기능을 제공합니다.\n",
    "\n",
    "# 참고: https://docs.pinecone.io/guides/indexes/choose-a-pod-type-and-size\n",
    "# import os\n",
    "# from langchain_teddynote.community.pinecone import create_index\n",
    "# from pinecone import PodSpec\n",
    "\n",
    "# # Pinecone 인덱스 생성\n",
    "# pc_index = create_index(\n",
    "#     api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "#     index_name=\"jaehonote\",  # 인덱스 이름을 지정합니다.\n",
    "#     dimension=1536,  # Embedding 차원과 맞춥니다. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "#     metric=\"dotproduct\",  # 유사도 측정 방법을 지정합니다. (dotproduct, euclidean, cosine)\n",
    "#     pod_spec=PodSpec(\n",
    "#         environment=\"us-west1-gcp\", pod_type=\"p1.x1\", pods=1\n",
    "#     ),  # 유료 Pod 사용\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Encoder 생성\n",
    "- Sparse Encoder 를 생성합니다.\n",
    "- `Kiwi Tokenizer` 와 한글 불용어(stopwords) 처리를 수행합니다. 내재화 되어있는 인코더는 영어로 맞춰줘 있다. 한글로 맞추기 위해 사용한다.\n",
    "- Sparse Encoder 를 활용하여 contents 를 학습합니다. 여기서 학습한 인코드는 VectorStore 에 문서를 저장할 때 Sparse Vector 를 생성할 때 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.korean import stopwords\n",
    "from langchain_teddynote.community.pinecone import create_sparse_encoder, fit_sparse_encoder\n",
    "\n",
    "stopword = stopwords()\n",
    "stopword\n",
    "\n",
    "# 한글 불용어 사전 stopwords() + Kiwi 형태소 분석기\n",
    "sparse_encoder = create_sparse_encoder(stopwords(), mode='kiwi') # 한글처리를 하기위한 kiwi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse Encoder를 Corpus에 학습한다.\n",
    "- `save_path`: Sparse Encoder를 저장할 경로. 추후에 `pikcle`형식으로 저장한 Sparse Encoder를 불러와 Query임베딩할떄 사용한다. 따라서 저장할 경로를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe33eb8029949b0bc30f040d799a985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fit_sparse_encoder]\n",
      "Saved Sparse Encoder to: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sparse Encoder를 사용하여 contents를 학습\n",
    "save_path = fit_sparse_encoder(\n",
    "    sparse_encoder=sparse_encoder, contents=contents, save_path=\"./sparse_encoder.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[선택사항] 나중에 학습을 저장한 Sparse Encoder를 다시 불러올떄 사용하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_sparse_encoder]\n",
      "Loaded Sparse Encoder from: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# 저장한 sparse encoder불러오기\n",
    "from langchain_teddynote.community.pinecone import load_sparse_encoder\n",
    "\n",
    "sparse_encoder = load_sparse_encoder(\"./sparse_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone: DB Index에 추가 (Upsert)\n",
    "Upsert: update + insert\n",
    "- `context`: 문서의 내용입니다.\n",
    "- `page`: 문서의 페이지 번호입니다.\n",
    "- `source`: 문서의 출처입니다.\n",
    "- `values`: Embedder 를 통해 얻은 문서의 임베딩입니다.\n",
    "- `sparse values`: Sparse Encoder 를 통해 얻은 문서의 임베딩입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac96da6bf0240b6ae60d30b28de3e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      4\u001b[0m openai_embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mupsert_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpc_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#picone 인덱스\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjaehonote-namespace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#파인콘 namespace. 비슷한 문서에는 같은 namespace에 저장\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 이전에 처리한 문서내용\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 이전에 처리한 문서 데이터 \u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Sparse Encoder\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:158\u001b[0m, in \u001b[0;36mupsert_documents\u001b[1;34m(index, namespace, contents, metadatas, sparse_encoder, embedder, batch_size)\u001b[0m\n\u001b[0;32m    144\u001b[0m     sparse_embeds \u001b[38;5;241m=\u001b[39m sparse_encoder\u001b[38;5;241m.\u001b[39mencode_documents(context_batch)\n\u001b[0;32m    146\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    147\u001b[0m         {\n\u001b[0;32m    148\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: _id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         )\n\u001b[0;32m    156\u001b[0m     ]\n\u001b[1;32m--> 158\u001b[0m     \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[upsert_documents]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m.\u001b[39mdescribe_index_stats()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\pinecone\\grpc\\index_grpc.py:144\u001b[0m, in \u001b[0;36mGRPCIndex.upsert\u001b[1;34m(self, vectors, async_req, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PineconeGrpcFuture(future)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\pinecone\\grpc\\index_grpc.py:177\u001b[0m, in \u001b[0;36mGRPCIndex._upsert_batch\u001b[1;34m(self, vectors, namespace, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_non_empty_args([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m, namespace)])\n\u001b[0;32m    176\u001b[0m request \u001b[38;5;241m=\u001b[39m UpsertRequest(vectors\u001b[38;5;241m=\u001b[39mvectors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs_dict)\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_grpc_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUpsert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\pinecone\\grpc\\base.py:182\u001b[0m, in \u001b[0;36mGRPCIndexBase._wrap_grpc_call\u001b[1;34m(self, func, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m _InactiveRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PineconeException(e\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdebug_error_string) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\pinecone\\grpc\\base.py:171\u001b[0m, in \u001b[0;36mGRPCIndexBase._wrap_grpc_call.<locals>.wrapped\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m _metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    163\u001b[0m     (k, v)\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m     }\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _InactiveRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeException(e\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mdebug_error_string) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\grpc\\_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1168\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1175\u001b[0m     (\n\u001b[0;32m   1176\u001b[0m         state,\n\u001b[0;32m   1177\u001b[0m         call,\n\u001b[1;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\grpc\\_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[0;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[0;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:395\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:207\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:201\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "from langchain_teddynote.community.pinecone import upsert_documents\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "openai_embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "upsert_documents(\n",
    "    index=pc_index, #picone 인덱스\n",
    "    namespace=\"jaehonote-namespace-0\", #파인콘 namespace. 비슷한 문서에는 같은 namespace에 저장\n",
    "    contents=contents, # 이전에 처리한 문서내용\n",
    "    metadatas=metadatas, # 이전에 처리한 문서 데이터 \n",
    "    sparse_encoder=sparse_encoder, # Sparse Encoder\n",
    "    embedder=openai_embeddings,\n",
    "    batch_size=32,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe6df89522c438fa04ace9cfc404d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "문서 Upsert 중:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 617개의 Vector 가 Upsert 되었습니다.\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'jaehonote-namespace': {'vector_count': 882}},\n",
      " 'total_vector_count': 882}\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "from langchain_teddynote.community.pinecone import upsert_documents\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_teddynote.community.pinecone import upsert_documents_parallel\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "upsert_documents_parallel(\n",
    "    index=pc_index, #picone 인덱스\n",
    "    namespace=\"jaehonote-namespace-1\", #파인콘 namespace. 비슷한 문서에는 같은 namespace에 저장\n",
    "    contents=contents, # 이전에 처리한 문서내용\n",
    "    metadatas=metadatas, # 이전에 처리한 문서 데이터 \n",
    "    sparse_encoder=sparse_encoder, # Sparse Encoder\n",
    "    embedder=openai_embeddings,\n",
    "    batch_size=64, #chunk size * batch_size. 값이 너무크면 에러가난다. 1000*64\n",
    "    max_workers=30, # 위 업데이트를 30명이 동시에 처리하는것. 1000*64을 30명에서 한다고 생각하면됌. 엄청빠름! 약 1분을 6초로 줄여버렸다!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인덱스 조회/삭제\n",
    "`describe_index_stats` 메서드는 인덱스의 내용에 대한 통계 정보를 제공합니다. 이 메서드를 통해 네임스페이스별 벡터 수와 차원 수 등의 정보를 얻을 수 있습니다.\n",
    "\n",
    "**매개변수**\n",
    "- filter (Optional[Dict[str, Union[str, float, int, bool, List, dict]]]): 특정 조건에 맞는 벡터들에 대한 통계만 반환하도록 하는 필터. 기본값은 None\n",
    "- **kwargs: 추가 키워드 인자\n",
    "\n",
    "**반환값**\n",
    "- DescribeIndexStatsResponse: 인덱스에 대한 통계 정보를 담고 있는 객체\n",
    "\n",
    "**사용 예시**\n",
    "- 기본 사용: index.describe_index_stats()\n",
    "- 필터 적용: index.describe_index_stats(filter={'key': 'value'})\n",
    "\n",
    "**참고**\n",
    "- metadata 필터링은 유료 사용자에 한하여 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'jaehonote-namespace': {'vector_count': 1458}},\n",
       " 'total_vector_count': 1458}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 조회\n",
    "pc_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네임스페이스 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import delete_namespace\n",
    "\n",
    "delete_namespace(\n",
    "    pinecone_index=pc_index,\n",
    "    namespace=\"jaehonote-namespace-0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 조회\n",
    "pc_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유료사용자 전용 기능: metadata의 filter기능. \n",
    "\n",
    "$eq은 일치기능 SPRi AI Brief_8월호_산업동향.pdf만 지워줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import delete_by_filter\n",
    "\n",
    "# metadata 필터링(유료 기능) 으로 삭제\n",
    "delete_by_filter(\n",
    "    pinecone_index=pc_index,\n",
    "    namespace=\"teddynote-namespace-01\",\n",
    "    filter={\"source\": {\"$eq\": \"SPRi AI Brief_8월호_산업동향.pdf\"}},\n",
    ")\n",
    "pc_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색기(Retriever) 생성\n",
    "\n",
    "### PineconeKiwiHybridRetriever 초기화 파라미터 설정\n",
    "\n",
    "`init_pinecone_index` 함수와 `PineconeKiwiHybridRetriever` 클래스는 Pinecone을 사용한 하이브리드 검색 시스템을 구현합니다. 이 시스템은 밀집 벡터와 희소 벡터를 결합하여 효과적인 문서 검색을 수행합니다.\n",
    "\n",
    "**Pinecone 인덱스 초기화**\n",
    "\n",
    "`init_pinecone_index` 함수는 Pinecone 인덱스를 초기화하고 필요한 구성 요소를 설정합니다.\n",
    "\n",
    "**매개변수**\n",
    "* `index_name` (str): Pinecone 인덱스 이름\n",
    "* `namespace` (str): 사용할 네임스페이스\n",
    "* `api_key` (str): Pinecone API 키\n",
    "* `sparse_encoder_pkl_path` (str): 희소 인코더 피클 파일 경로\n",
    "* `stopwords` (List[str]): 불용어 리스트\n",
    "* `tokenizer` (str): 사용할 토크나이저 (기본값: \"kiwi\")\n",
    "* `embeddings` (Embeddings): 임베딩 모델\n",
    "* `top_k` (int): 반환할 최대 문서 수 (기본값: 10)\n",
    "* `alpha` (float): 밀집 벡터와 희소 벡터의 가중치 조절 파라미터 (기본값: 0.5)\n",
    "\n",
    "**주요 기능**\n",
    "1. Pinecone 인덱스 초기화 및 통계 정보 출력\n",
    "2. 희소 인코더(BM25) 로딩 및 토크나이저 설정\n",
    "3. 네임스페이스 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init_pinecone_index]\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'jaehonote-namespace': {'vector_count': 1458}},\n",
      " 'total_vector_count': 1458}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import init_pinecone_index\n",
    "\n",
    "pinecone_params = init_pinecone_index(\n",
    "    index_name=\"jaeho-note-index\",  # Pinecone 인덱스 이름\n",
    "    namespace=\"jaehonote-namespace\",  # Pinecone Namespace\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],  # Pinecone API Key\n",
    "    sparse_encoder_path=\"./sparse_encoder.pkl\",  # Sparse Encoder 저장경로(save_path)\n",
    "    stopwords=stopwords(),  # 불용어 사전\n",
    "    tokenizer=\"kiwi\",\n",
    "    embeddings=openai_embeddings,  # Dense Embedder\n",
    "    top_k=5,  # Top-K 문서 반환 개수\n",
    "    alpha=0.5,  # alpha=0.75로 설정한 경우, (0.75: Dense Embedding, 0.25: Sparse Embedding)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PineconeKiwiHybridRetriever\n",
    "\n",
    "`PineconeKiwiHybridRetriever` 클래스는 Pinecone과 Kiwi를 결합한 하이브리드 검색기를 구현합니다.\n",
    "\n",
    "**주요 속성**\n",
    "* `embeddings`: 밀집 벡터 변환용 임베딩 모델\n",
    "* `sparse_encoder`: 희소 벡터 변환용 인코더\n",
    "* `index`: Pinecone 인덱스 객체\n",
    "* `top_k`: 반환할 최대 문서 수\n",
    "* `alpha`: 밀집 벡터와 희소 벡터의 가중치 조절 파라미터\n",
    "* `namespace`: Pinecone 인덱스 내 네임스페이스\n",
    "\n",
    "**특징**\n",
    "* 밀집 벡터와 희소 벡터를 결합한 HybridSearch Retriever\n",
    "* 가중치 조절을 통한 검색 전략 최적화 가능\n",
    "* 다양한 동적 metadata 필터링 적용 가능(`search_kwargs` 사용: `filter`, `k`, `rerank`, `rerank_model`, `top_n` 등)\n",
    "\n",
    "**사용 예시**\n",
    "1. `init_pinecone_index` 함수로 필요한 구성 요소 초기화\n",
    "2. 초기화된 구성 요소로 `PineconeKiwiHybridRetriever` 인스턴스 생성\n",
    "3. 생성된 검색기를 사용하여 하이브리드 검색 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetriever\n",
    "\n",
    "# 검색기 생성\n",
    "pinecone_retriever = PineconeKiwiHybridRetriever(**pinecone_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수\n",
      "KEY Contents\n",
      "n 주요 LLM의 환각 현상을 평가한 ‘LLM 환각 지수’에 따르면 GPT-4는 작업 유형과 관계없이\n",
      "가장 우수한 성능을 보였으며 GPT-3.5도 거의 동등한 성능을 발휘\n",
      "n 오픈소스 모델 중에서는 메타의 라마2가 RAG 없는 질문과 답변 및 긴 형식의 텍스트\n",
      "생성에서 가장 우수한 성능을 발휘\n",
      "£주요 LLM 중 GPT-4가 가장 환각 현상 적고 GPT-3.5 터보도 비슷한 성능 기록\n",
      "n 머신러닝 데이터 관리 기업 갈릴레오(Galileo)가 2023년 11월 15일 주요 LLM의 환각 현상을 평가한\n",
      "‘LLM 환각 지수(LLM Hallucination Index)’를 발표\n",
      "∙ 생성 AI의 환각 현상은 AI 시스템이 잘못된 정보를 생성하거나, 현실과 다른 부정확한 결과를 내놓는\n",
      "현상으로, 기업의 AI 도입을 가로막는 주요 장애물이며, 환각 지수는 신뢰할 수 있는 생성 AI 구축을 위해\n",
      "환각을 평가하고 측정하는 구조화된 접근방식을 제공\n",
      "∙ 환각 지수는 △검색 증강 생성(Retrieval-Augmented Generation, RAG)*을 포함한 질문과 답변 △RAG\n",
      "없는 질문과 답변 △긴 형식의 텍스트(보고서나 기사, 에세이) 생성의 3개 작업 유형에 대하여 환각을\n",
      "기준으로 LLM의 순위를 평가\n",
      "* 기존에 학습된 데이터가 아닌 외부 소스(데이터셋, 데이터베이스, 문서 등)에서 가져온 정보를 검색해 활용하는 기술\n",
      "n 3개의 작업 유형 평가 전체에서 오픈AI의 GPT-4가 최고의 성능을 기록했으며, GPT-3.5 터보도\n",
      "GPT-4와 거의 동등한 성능을 발휘\n",
      "∙ 메타의 라마2(Llama-2-70b)는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴\n",
      "형식의 텍스트 생성에서도 GPT-4에 준하는 성능을 기록했으나, RAG 포함 질문과 답변에서는 허깅\n",
      "페이스의 제퍼(Zephyr-7b)가 라마2를 능가\n",
      "{'page': 19.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.20610565}\n",
      "\n",
      "====================\n",
      "\n",
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수\n",
      "KEY Contents\n",
      "n 주요 LLM의 환각 현상을 평가한 ‘LLM 환각 지수’에 따르면 GPT-4는 작업 유형과 관계없이\n",
      "가장 우수한 성능을 보였으며 GPT-3.5도 거의 동등한 성능을 발휘\n",
      "n 오픈소스 모델 중에서는 메타의 라마2가 RAG 없는 질문과 답변 및 긴 형식의 텍스트\n",
      "생성에서 가장 우수한 성능을 발휘\n",
      "£주요 LLM 중 GPT-4가 가장 환각 현상 적고 GPT-3.5 터보도 비슷한 성능 기록\n",
      "n 머신러닝 데이터 관리 기업 갈릴레오(Galileo)가 2023년 11월 15일 주요 LLM의 환각 현상을 평가한\n",
      "‘LLM 환각 지수(LLM Hallucination Index)’를 발표\n",
      "∙ 생성 AI의 환각 현상은 AI 시스템이 잘못된 정보를 생성하거나, 현실과 다른 부정확한 결과를 내놓는\n",
      "현상으로, 기업의 AI 도입을 가로막는 주요 장애물이며, 환각 지수는 신뢰할 수 있는 생성 AI 구축을 위해\n",
      "환각을 평가하고 측정하는 구조화된 접근방식을 제공\n",
      "∙ 환각 지수는 △검색 증강 생성(Retrieval-Augmented Generation, RAG)*을 포함한 질문과 답변 △RAG\n",
      "없는 질문과 답변 △긴 형식의 텍스트(보고서나 기사, 에세이) 생성의 3개 작업 유형에 대하여 환각을\n",
      "기준으로 LLM의 순위를 평가\n",
      "* 기존에 학습된 데이터가 아닌 외부 소스(데이터셋, 데이터베이스, 문서 등)에서 가져온 정보를 검색해 활용하는 기술\n",
      "n 3개의 작업 유형 평가 전체에서 오픈AI의 GPT-4가 최고의 성능을 기록했으며, GPT-3.5 터보도\n",
      "GPT-4와 거의 동등한 성능을 발휘\n",
      "∙ 메타의 라마2(Llama-2-70b)는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴\n",
      "형식의 텍스트 생성에서도 GPT-4에 준하는 성능을 기록했으나, RAG 포함 질문과 답변에서는 허깅\n",
      "페이스의 제퍼(Zephyr-7b)가 라마2를 능가\n",
      "{'page': 19.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.2060554}\n",
      "\n",
      "====================\n",
      "\n",
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출\n",
      "KEY Contents\n",
      "n 미국 FTC는 저작권청이 실시한 저작권과 AI 관련 질의공고에 대하여 소비자 보호와 경쟁\n",
      "측면의 의견을 제시\n",
      "n FTC는 생성 AI로 인한 창작자와 소비자 피해의 가능성에 우려를 표시하는 한편, 일부\n",
      "빅테크가 막대한 재원을 활용해 시장 지배력을 더욱 강화할 수 있다는 우려를 제기\n",
      "£FTC, 생성 AI로 인한 소비자와 창작자의 피해 및 빅테크의 시장 지배력 강화 우려\n",
      "n 미국 연방거래위원회(FTC)가 2023년 10월 30일 저작권청(U.S. Copyright Office, USCO)이\n",
      "지난 9월 발표한 저작권과 AI 관련 질의공고(Notice of Inquiry, NOI)에 대한 의견서를 발표\n",
      "∙ 저작권청은 생성 AI와 관련된 저작권법과 정책 이슈를 조사하고 있으며, 폭넓은 의견 수렴을 통해\n",
      "입법과 규제 조치의 필요성을 검토할 계획\n",
      "∙ FTC는 생성 AI의 개발과 배포가 소비자, 근로자, 중소기업에 피해를 줄 수 있다며 소비자의 개인정보\n",
      "침해, 차별과 편견의 자동화, 사기 범죄 등 AI 사용과 관련된 위험에 주목\n",
      "n FTC는 저작권법에 따른 권리와 책임 범위를 넘어서는 저작권 문제에 주목하여 생성 AI로 인해\n",
      "창작자의 경쟁력이 불공정한 피해를 볼 수 있으며, 소비자가 특정 창작자의 작품을 생성 AI가\n",
      "만들었다고 오해할 소지가 있다고 지적\n",
      "∙ 저작권법에 저촉되는 행위는 불공정 경쟁이나 기만행위에도 해당될 수 있으며, 창작자의 평판 악화,\n",
      "저작물의 가치 저하나 개인정보 유출로 소비자에 상당한 피해를 초래 가능\n",
      "n FTC는 일부 빅테크가 막대한 재원을 활용해 생성 AI 사용자의 이탈을 막고 저작권이 있는 상용\n",
      "데이터에 대한 독점 라이선스를 확보해 시장 지배력을 더욱 강화할 수 있다는 우려도 제기\n",
      "{'page': 7.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.20113166}\n",
      "\n",
      "====================\n",
      "\n",
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출\n",
      "KEY Contents\n",
      "n 미국 FTC는 저작권청이 실시한 저작권과 AI 관련 질의공고에 대하여 소비자 보호와 경쟁\n",
      "측면의 의견을 제시\n",
      "n FTC는 생성 AI로 인한 창작자와 소비자 피해의 가능성에 우려를 표시하는 한편, 일부\n",
      "빅테크가 막대한 재원을 활용해 시장 지배력을 더욱 강화할 수 있다는 우려를 제기\n",
      "£FTC, 생성 AI로 인한 소비자와 창작자의 피해 및 빅테크의 시장 지배력 강화 우려\n",
      "n 미국 연방거래위원회(FTC)가 2023년 10월 30일 저작권청(U.S. Copyright Office, USCO)이\n",
      "지난 9월 발표한 저작권과 AI 관련 질의공고(Notice of Inquiry, NOI)에 대한 의견서를 발표\n",
      "∙ 저작권청은 생성 AI와 관련된 저작권법과 정책 이슈를 조사하고 있으며, 폭넓은 의견 수렴을 통해\n",
      "입법과 규제 조치의 필요성을 검토할 계획\n",
      "∙ FTC는 생성 AI의 개발과 배포가 소비자, 근로자, 중소기업에 피해를 줄 수 있다며 소비자의 개인정보\n",
      "침해, 차별과 편견의 자동화, 사기 범죄 등 AI 사용과 관련된 위험에 주목\n",
      "n FTC는 저작권법에 따른 권리와 책임 범위를 넘어서는 저작권 문제에 주목하여 생성 AI로 인해\n",
      "창작자의 경쟁력이 불공정한 피해를 볼 수 있으며, 소비자가 특정 창작자의 작품을 생성 AI가\n",
      "만들었다고 오해할 소지가 있다고 지적\n",
      "∙ 저작권법에 저촉되는 행위는 불공정 경쟁이나 기만행위에도 해당될 수 있으며, 창작자의 평판 악화,\n",
      "저작물의 가치 저하나 개인정보 유출로 소비자에 상당한 피해를 초래 가능\n",
      "n FTC는 일부 빅테크가 막대한 재원을 활용해 생성 AI 사용자의 이탈을 막고 저작권이 있는 상용\n",
      "데이터에 대한 독점 라이선스를 확보해 시장 지배력을 더욱 강화할 수 있다는 우려도 제기\n",
      "{'page': 7.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.20110664}\n",
      "\n",
      "====================\n",
      "\n",
      "▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································13\n",
      "▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화····························································14\n",
      "3. 기술/연구\n",
      "▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표······························································15\n",
      "▹ 구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························16\n",
      "▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수 ···········································17\n",
      "4. 인력/교육\n",
      "▹ 영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아·······························18\n",
      "Ⅱ\n",
      ". 주요 행사\n",
      "▹CES 2024·····························································································································19\n",
      "▹AIMLA 2024·························································································································19\n",
      "▹AAAI Conference on Artificial Intelligence··································································19\n",
      "{'page': 1.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.19594887}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\"gpt-4o 미니 출시 관련 정보에 대해서 알려줘\")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화\n",
      "KEY Contents\n",
      "n 구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은\n",
      "구글과 클라우드 서비스 사용 계약도 체결\n",
      "n 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인\n",
      "앤스로픽 및 오픈AI와 협력을 확대하는 추세\n",
      "£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\n",
      "n 구글이 2023년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억\n",
      "달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\n",
      "∙ 구글은 2023년 2월 앤스로픽에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존도 지난 9월\n",
      "앤스로픽에 최대 40억 달러의 투자 계획을 공개\n",
      "∙ 한편, 2023년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해\n",
      "4년간 30억 달러 규모의 계약을 체결\n",
      "∙ 오픈AI 창업자 그룹의 일원이었던 다리오(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei)\n",
      "남매가 2021년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드(Claude)’ LLM을 개발\n",
      "n 아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈\n",
      "AI와 협력을 확대\n",
      "∙ 마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023년 1월 추가로 100억 달러를\n",
      "투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure)\n",
      "클라우드 플랫폼을 사용해 AI 모델을 훈련\n",
      "£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\n",
      "n 구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\n",
      "통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속\n",
      "{'page': 13.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.42183322}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽\", search_kwargs={\"alpha\": 1, \"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화\n",
      "KEY Contents\n",
      "n 구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은\n",
      "구글과 클라우드 서비스 사용 계약도 체결\n",
      "n 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인\n",
      "앤스로픽 및 오픈AI와 협력을 확대하는 추세\n",
      "£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\n",
      "n 구글이 2023년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억\n",
      "달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\n",
      "∙ 구글은 2023년 2월 앤스로픽에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존도 지난 9월\n",
      "앤스로픽에 최대 40억 달러의 투자 계획을 공개\n",
      "∙ 한편, 2023년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해\n",
      "4년간 30억 달러 규모의 계약을 체결\n",
      "∙ 오픈AI 창업자 그룹의 일원이었던 다리오(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei)\n",
      "남매가 2021년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드(Claude)’ LLM을 개발\n",
      "n 아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈\n",
      "AI와 협력을 확대\n",
      "∙ 마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023년 1월 추가로 100억 달러를\n",
      "투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure)\n",
      "클라우드 플랫폼을 사용해 AI 모델을 훈련\n",
      "£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\n",
      "n 구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\n",
      "통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속\n",
      "{'page': 13.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.7921144}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽\", search_kwargs={\"alpha\": 0, \"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동적 `search_kwargs` 사용\n",
    "- `filter`: metadata 필터링 적용\n",
    "\n",
    "(예시) `page` 가 5보다 작은 문서만 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023년 12월호\n",
      "Ⅰ\n",
      ". 인공지능 산업 동향 브리프\n",
      "1. 정책/법제\n",
      "▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ·························1\n",
      "▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의···························2\n",
      "▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언···························3\n",
      "▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각·····································4\n",
      "▹ 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출·················5\n",
      "▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항···················································6\n",
      "2. 기업/산업\n",
      "▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································7\n",
      "▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ·······································8\n",
      "▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································9\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12\n",
      "{'page': 1.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.1800869}\n",
      "\n",
      "====================\n",
      "\n",
      "2023년 12월호\n",
      "Ⅰ\n",
      ". 인공지능 산업 동향 브리프\n",
      "1. 정책/법제\n",
      "▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ·························1\n",
      "▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의···························2\n",
      "▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언···························3\n",
      "▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각·····································4\n",
      "▹ 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출·················5\n",
      "▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항···················································6\n",
      "2. 기업/산업\n",
      "▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································7\n",
      "▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ·······································8\n",
      "▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································9\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12\n",
      "{'page': 1.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.18006735}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 claude 출시 관련 내용을 알려줘\",\n",
    "    search_kwargs={\"filter\": {\"page\": {\"$lt\": 5}}, \"k\": 2},\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동적 `search_kwargs` 사용\n",
    "- `filter`: metadata 필터링 적용\n",
    "\n",
    "(예시) `source` 가 `SPRi AI Brief_8월호_산업동향.pdf` 문서내 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 claude 3.5 출시 관련 내용을 알려줘\",\n",
    "    search_kwargs={\n",
    "        \"filter\": {\"source\": {\"$eq\": \"SPRi AI Brief_7월호_산업동향.pdf\"}},\n",
    "        \"k\": 3,\n",
    "    },\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking 적용\n",
    "\n",
    "아직은 `pre` 기능입니다.\n",
    "\n",
    "- 동적 reranking 기능을 구현해 놓았지만, pinecone 라이브러리 의존성에 문제가 있을 수 있습니다.\n",
    "- 따라서, 아래 코드는 향후 의존성 해결 후 원활하게 동작할 수 있습니다.\n",
    "\n",
    "참고 문서: https://docs.pinecone.io/guides/inference/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rerank_documents]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GRPCIndex' object has no attribute 'inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 실행 결과\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m search_results \u001b[38;5;241m=\u001b[39m \u001b[43mpinecone_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m앤스로픽의 클로드 소넷\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrerank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrerank_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbge-reranker-v2-m3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_n\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mpage_content)\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_core\\retrievers.py:253\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    252\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    256\u001b[0m         result,\n\u001b[0;32m    257\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_core\\retrievers.py:246\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 246\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:376\u001b[0m, in \u001b[0;36mPineconeKiwiHybridRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **search_kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# Rerank 옵션이 있는 경우 rerank 수행\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_kwargs\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrerank\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    375\u001b[0m ):\n\u001b[1;32m--> 376\u001b[0m     documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rerank_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:499\u001b[0m, in \u001b[0;36mPineconeKiwiHybridRetriever._rerank_documents\u001b[1;34m(self, query, documents, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m top_n \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_n\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(documents))\n\u001b[0;32m    495\u001b[0m rerank_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    496\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(i), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc\u001b[38;5;241m.\u001b[39mpage_content} \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents)\n\u001b[0;32m    497\u001b[0m ]\n\u001b[1;32m--> 499\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241m.\u001b[39mrerank(\n\u001b[0;32m    500\u001b[0m     model\u001b[38;5;241m=\u001b[39mrerank_model,\n\u001b[0;32m    501\u001b[0m     query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m    502\u001b[0m     documents\u001b[38;5;241m=\u001b[39mrerank_docs,\n\u001b[0;32m    503\u001b[0m     top_n\u001b[38;5;241m=\u001b[39mtop_n,\n\u001b[0;32m    504\u001b[0m     return_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# 재정렬된 결과를 기반으로 문서 리스트 재구성\u001b[39;00m\n\u001b[0;32m    508\u001b[0m reranked_documents \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GRPCIndex' object has no attribute 'inference'"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 클로드 소넷\",\n",
    "    search_kwargs={\"rerank\": True, \"rerank_model\": \"bge-reranker-v2-m3\", \"top_n\": 3},\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-gLkynrUQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
