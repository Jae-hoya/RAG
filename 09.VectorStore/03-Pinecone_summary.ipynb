{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 문서 전처리\n",
    "\n",
    "`from langchain_teddynote.community.pinecone import preprocess_documents`\n",
    "\n",
    "2. vectorstore index 생성\n",
    "\n",
    "`from langchain_teddynote.community.pinecone import create_index`\n",
    "\n",
    "3. sparse encoder생성\n",
    "\n",
    "`from langchain_teddynote.community.pinecone import create_sparse_encoder`\n",
    "\n",
    "4. db 인덱스에 update + insert (upsert) - contents와 metadatas를 추가\n",
    "\n",
    "`from langchain_teddynote.community.pinecone import upsert_documents`\n",
    "\n",
    "5. hybrid search\n",
    "\n",
    "`from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetrieverm`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import glob\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "split_docs = []\n",
    "\n",
    "# 텍스트 파일을 load -> List[Document] 형태로 변환\n",
    "files = sorted(glob.glob(\"data/*.pdf\"))\n",
    "for file in files:\n",
    "    loader = PDFPlumberLoader(file)\n",
    "    split_docs.extend(loader.load_and_split(text_splitter))\n",
    "\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서의 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2978469d65b44a0a924f76aae04fc02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 저장하고 싶은 메타데이터만 뽑는다.\n",
    "from langchain_teddynote.community.pinecone import preprocess_documents\n",
    "\n",
    "contents, metadatas = preprocess_documents(\n",
    "    split_docs=split_docs,\n",
    "    #metadata_keys=[\"source\", \"page\", \"author\"],\n",
    "    metadata_keys=[\"source\", \"page\"],\n",
    "    min_length=5, #문서의 길이를 가지고 filtering. 5글자 이상의 문서만을 사용. (예를들어 숫자만 있거나 제목만 있는경우) 줄어든것을 확인할 수 있다.\n",
    "    use_basename=True # False인 경우 폴더 위치까지 모두 적혀있다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로운 VectorStore 인덱스 생성\n",
    "**주의사항**\n",
    "\n",
    "- metric 은 유사도 측정 방법을 지정합니다. 만약 HybridSearch 를 고려하고 있다면 metric 은 dotproduct 로 지정합니다. 파인콘 홈페이지에서도 생성 가능 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[create_index]\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'jaehonote-namespace': {'vector_count': 1458}},\n",
      " 'total_vector_count': 1458}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_teddynote.community.pinecone import create_index\n",
    "\n",
    "pc_index = create_index(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    index_name=\"jaeho-note-index\", # 인덱스 이름을 지정합니다.\n",
    "    dimension=1536, # Embedding 차원과 맞춥니다. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "    metric=\"dotproduct\" # 유사도 측정 방법을 지정합니다. (dotproduct, euclidean, cosine) Hybrid search를 위해선 dotproduct를 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래는 유료 Pod 를 사용하는 예시입니다. 유료 Pod 는 무료 Serverless Pod 대비 더 확장된 기능을 제공합니다.\n",
    "\n",
    "# 참고: https://docs.pinecone.io/guides/indexes/choose-a-pod-type-and-size\n",
    "# import os\n",
    "# from langchain_teddynote.community.pinecone import create_index\n",
    "# from pinecone import PodSpec\n",
    "\n",
    "# # Pinecone 인덱스 생성\n",
    "# pc_index = create_index(\n",
    "#     api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "#     index_name=\"teddynote-db-index2\",  # 인덱스 이름을 지정합니다.\n",
    "#     dimension=4096,  # Embedding 차원과 맞춥니다. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "#     metric=\"dotproduct\",  # 유사도 측정 방법을 지정합니다. (dotproduct, euclidean, cosine)\n",
    "#     pod_spec=PodSpec(\n",
    "#         environment=\"us-west1-gcp\", pod_type=\"p1.x1\", pods=1\n",
    "#     ),  # 유료 Pod 사용\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Encoder 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.korean import stopwords\n",
    "from langchain_teddynote.community.pinecone import create_sparse_encoder, fit_sparse_encoder\n",
    "\n",
    "stopword = stopwords()\n",
    "stopword\n",
    "\n",
    "# 한글 불용어 사전 stopwords() + Kiwi 형태소 분석기\n",
    "sparse_encoder = create_sparse_encoder(stopwords(), mode='kiwi') # 한글처리를 하기위한 kiwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff71f6eda2847bca3466a6d0dd7780c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/619 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fit_sparse_encoder]\n",
      "Saved Sparse Encoder to: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sparse Encoder를 사용하여 contents를 학습\n",
    "save_path = fit_sparse_encoder(\n",
    "    sparse_encoder=sparse_encoder, contents=contents, save_path=\"./sparse_encoder.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[선택사항] 나중에 학습을 저장한 Sparse Encoder를 다시 불러올떄 사용하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_sparse_encoder]\n",
      "Loaded Sparse Encoder from: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import load_sparse_encoder\n",
    "\n",
    "sparse_encoder = load_sparse_encoder(\"./sparse_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone: DB Index에 추가 (Upsert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63255326a654f9fa2b1cdf732d74937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[upsert_documents]\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'jaehonote-namespace': {'vector_count': 1458},\n",
      "                'jaehonote-namespace-0': {'vector_count': 608}},\n",
      " 'total_vector_count': 2066}\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "from langchain_teddynote.community.pinecone import upsert_documents\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "openai_embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "upsert_documents(\n",
    "    index=pc_index, #picone 인덱스\n",
    "    namespace=\"jaehonote-namespace-0\", #파인콘 namespace. 비슷한 문서에는 같은 namespace에 저장\n",
    "    contents=contents, # 이전에 처리한 문서내용\n",
    "    metadatas=metadatas, # 이전에 처리한 문서 데이터 \n",
    "    sparse_encoder=sparse_encoder, # Sparse Encoder\n",
    "    embedder=openai_embeddings,\n",
    "    batch_size=32,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색기(Retriever) 생성\n",
    "\n",
    "### PineconeKiwiHybridRetriever 초기화 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init_pinecone_index]\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'jaehonote-namespace': {'vector_count': 1458},\n",
      "                'jaehonote-namespace-0': {'vector_count': 619}},\n",
      " 'total_vector_count': 2077}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import init_pinecone_index\n",
    "\n",
    "pinecone_params = init_pinecone_index(\n",
    "    index_name=\"jaeho-note-index\",  # Pinecone 인덱스 이름\n",
    "    namespace=\"jaehonote-namespace\",  # Pinecone Namespace\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],  # Pinecone API Key\n",
    "    sparse_encoder_path=\"./sparse_encoder.pkl\",  # Sparse Encoder 저장경로(save_path)\n",
    "    stopwords=stopwords(),  # 불용어 사전\n",
    "    tokenizer=\"kiwi\",\n",
    "    embeddings=openai_embeddings,  # Dense Embedder\n",
    "    top_k=5,  # Top-K 문서 반환 개수\n",
    "    alpha=0.5,  # alpha=0.75로 설정한 경우, (0.75: Dense Embedding, 0.25: Sparse Embedding)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PineconeKiwiHybridRetriever\n",
    "\n",
    "`PineconeKiwiHybridRetriever` 클래스는 Pinecone과 Kiwi를 결합한 하이브리드 검색기를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetriever\n",
    "\n",
    "# 검색기 생성\n",
    "pinecone_retriever = PineconeKiwiHybridRetriever(**pinecone_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수\n",
      "KEY Contents\n",
      "n 주요 LLM의 환각 현상을 평가한 ‘LLM 환각 지수’에 따르면 GPT-4는 작업 유형과 관계없이\n",
      "가장 우수한 성능을 보였으며 GPT-3.5도 거의 동등한 성능을 발휘\n",
      "n 오픈소스 모델 중에서는 메타의 라마2가 RAG 없는 질문과 답변 및 긴 형식의 텍스트\n",
      "생성에서 가장 우수한 성능을 발휘\n",
      "£주요 LLM 중 GPT-4가 가장 환각 현상 적고 GPT-3.5 터보도 비슷한 성능 기록\n",
      "n 머신러닝 데이터 관리 기업 갈릴레오(Galileo)가 2023년 11월 15일 주요 LLM의 환각 현상을 평가한\n",
      "‘LLM 환각 지수(LLM Hallucination Index)’를 발표\n",
      "∙ 생성 AI의 환각 현상은 AI 시스템이 잘못된 정보를 생성하거나, 현실과 다른 부정확한 결과를 내놓는\n",
      "현상으로, 기업의 AI 도입을 가로막는 주요 장애물이며, 환각 지수는 신뢰할 수 있는 생성 AI 구축을 위해\n",
      "환각을 평가하고 측정하는 구조화된 접근방식을 제공\n",
      "∙ 환각 지수는 △검색 증강 생성(Retrieval-Augmented Generation, RAG)*을 포함한 질문과 답변 △RAG\n",
      "없는 질문과 답변 △긴 형식의 텍스트(보고서나 기사, 에세이) 생성의 3개 작업 유형에 대하여 환각을\n",
      "기준으로 LLM의 순위를 평가\n",
      "* 기존에 학습된 데이터가 아닌 외부 소스(데이터셋, 데이터베이스, 문서 등)에서 가져온 정보를 검색해 활용하는 기술\n",
      "n 3개의 작업 유형 평가 전체에서 오픈AI의 GPT-4가 최고의 성능을 기록했으며, GPT-3.5 터보도\n",
      "GPT-4와 거의 동등한 성능을 발휘\n",
      "∙ 메타의 라마2(Llama-2-70b)는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴\n",
      "형식의 텍스트 생성에서도 GPT-4에 준하는 성능을 기록했으나, RAG 포함 질문과 답변에서는 허깅\n",
      "페이스의 제퍼(Zephyr-7b)가 라마2를 능가\n",
      "{'page': 19.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.20610565}\n",
      "\n",
      "====================\n",
      "\n",
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수\n",
      "KEY Contents\n",
      "n 주요 LLM의 환각 현상을 평가한 ‘LLM 환각 지수’에 따르면 GPT-4는 작업 유형과 관계없이\n",
      "가장 우수한 성능을 보였으며 GPT-3.5도 거의 동등한 성능을 발휘\n",
      "n 오픈소스 모델 중에서는 메타의 라마2가 RAG 없는 질문과 답변 및 긴 형식의 텍스트\n",
      "생성에서 가장 우수한 성능을 발휘\n",
      "£주요 LLM 중 GPT-4가 가장 환각 현상 적고 GPT-3.5 터보도 비슷한 성능 기록\n",
      "n 머신러닝 데이터 관리 기업 갈릴레오(Galileo)가 2023년 11월 15일 주요 LLM의 환각 현상을 평가한\n",
      "‘LLM 환각 지수(LLM Hallucination Index)’를 발표\n",
      "∙ 생성 AI의 환각 현상은 AI 시스템이 잘못된 정보를 생성하거나, 현실과 다른 부정확한 결과를 내놓는\n",
      "현상으로, 기업의 AI 도입을 가로막는 주요 장애물이며, 환각 지수는 신뢰할 수 있는 생성 AI 구축을 위해\n",
      "환각을 평가하고 측정하는 구조화된 접근방식을 제공\n",
      "∙ 환각 지수는 △검색 증강 생성(Retrieval-Augmented Generation, RAG)*을 포함한 질문과 답변 △RAG\n",
      "없는 질문과 답변 △긴 형식의 텍스트(보고서나 기사, 에세이) 생성의 3개 작업 유형에 대하여 환각을\n",
      "기준으로 LLM의 순위를 평가\n",
      "* 기존에 학습된 데이터가 아닌 외부 소스(데이터셋, 데이터베이스, 문서 등)에서 가져온 정보를 검색해 활용하는 기술\n",
      "n 3개의 작업 유형 평가 전체에서 오픈AI의 GPT-4가 최고의 성능을 기록했으며, GPT-3.5 터보도\n",
      "GPT-4와 거의 동등한 성능을 발휘\n",
      "∙ 메타의 라마2(Llama-2-70b)는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴\n",
      "형식의 텍스트 생성에서도 GPT-4에 준하는 성능을 기록했으나, RAG 포함 질문과 답변에서는 허깅\n",
      "페이스의 제퍼(Zephyr-7b)가 라마2를 능가\n",
      "{'page': 19.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.2060554}\n",
      "\n",
      "====================\n",
      "\n",
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출\n",
      "KEY Contents\n",
      "n 미국 FTC는 저작권청이 실시한 저작권과 AI 관련 질의공고에 대하여 소비자 보호와 경쟁\n",
      "측면의 의견을 제시\n",
      "n FTC는 생성 AI로 인한 창작자와 소비자 피해의 가능성에 우려를 표시하는 한편, 일부\n",
      "빅테크가 막대한 재원을 활용해 시장 지배력을 더욱 강화할 수 있다는 우려를 제기\n",
      "£FTC, 생성 AI로 인한 소비자와 창작자의 피해 및 빅테크의 시장 지배력 강화 우려\n",
      "n 미국 연방거래위원회(FTC)가 2023년 10월 30일 저작권청(U.S. Copyright Office, USCO)이\n",
      "지난 9월 발표한 저작권과 AI 관련 질의공고(Notice of Inquiry, NOI)에 대한 의견서를 발표\n",
      "∙ 저작권청은 생성 AI와 관련된 저작권법과 정책 이슈를 조사하고 있으며, 폭넓은 의견 수렴을 통해\n",
      "입법과 규제 조치의 필요성을 검토할 계획\n",
      "∙ FTC는 생성 AI의 개발과 배포가 소비자, 근로자, 중소기업에 피해를 줄 수 있다며 소비자의 개인정보\n",
      "침해, 차별과 편견의 자동화, 사기 범죄 등 AI 사용과 관련된 위험에 주목\n",
      "n FTC는 저작권법에 따른 권리와 책임 범위를 넘어서는 저작권 문제에 주목하여 생성 AI로 인해\n",
      "창작자의 경쟁력이 불공정한 피해를 볼 수 있으며, 소비자가 특정 창작자의 작품을 생성 AI가\n",
      "만들었다고 오해할 소지가 있다고 지적\n",
      "∙ 저작권법에 저촉되는 행위는 불공정 경쟁이나 기만행위에도 해당될 수 있으며, 창작자의 평판 악화,\n",
      "저작물의 가치 저하나 개인정보 유출로 소비자에 상당한 피해를 초래 가능\n",
      "n FTC는 일부 빅테크가 막대한 재원을 활용해 생성 AI 사용자의 이탈을 막고 저작권이 있는 상용\n",
      "데이터에 대한 독점 라이선스를 확보해 시장 지배력을 더욱 강화할 수 있다는 우려도 제기\n",
      "{'page': 7.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.20113166}\n",
      "\n",
      "====================\n",
      "\n",
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출\n",
      "KEY Contents\n",
      "n 미국 FTC는 저작권청이 실시한 저작권과 AI 관련 질의공고에 대하여 소비자 보호와 경쟁\n",
      "측면의 의견을 제시\n",
      "n FTC는 생성 AI로 인한 창작자와 소비자 피해의 가능성에 우려를 표시하는 한편, 일부\n",
      "빅테크가 막대한 재원을 활용해 시장 지배력을 더욱 강화할 수 있다는 우려를 제기\n",
      "£FTC, 생성 AI로 인한 소비자와 창작자의 피해 및 빅테크의 시장 지배력 강화 우려\n",
      "n 미국 연방거래위원회(FTC)가 2023년 10월 30일 저작권청(U.S. Copyright Office, USCO)이\n",
      "지난 9월 발표한 저작권과 AI 관련 질의공고(Notice of Inquiry, NOI)에 대한 의견서를 발표\n",
      "∙ 저작권청은 생성 AI와 관련된 저작권법과 정책 이슈를 조사하고 있으며, 폭넓은 의견 수렴을 통해\n",
      "입법과 규제 조치의 필요성을 검토할 계획\n",
      "∙ FTC는 생성 AI의 개발과 배포가 소비자, 근로자, 중소기업에 피해를 줄 수 있다며 소비자의 개인정보\n",
      "침해, 차별과 편견의 자동화, 사기 범죄 등 AI 사용과 관련된 위험에 주목\n",
      "n FTC는 저작권법에 따른 권리와 책임 범위를 넘어서는 저작권 문제에 주목하여 생성 AI로 인해\n",
      "창작자의 경쟁력이 불공정한 피해를 볼 수 있으며, 소비자가 특정 창작자의 작품을 생성 AI가\n",
      "만들었다고 오해할 소지가 있다고 지적\n",
      "∙ 저작권법에 저촉되는 행위는 불공정 경쟁이나 기만행위에도 해당될 수 있으며, 창작자의 평판 악화,\n",
      "저작물의 가치 저하나 개인정보 유출로 소비자에 상당한 피해를 초래 가능\n",
      "n FTC는 일부 빅테크가 막대한 재원을 활용해 생성 AI 사용자의 이탈을 막고 저작권이 있는 상용\n",
      "데이터에 대한 독점 라이선스를 확보해 시장 지배력을 더욱 강화할 수 있다는 우려도 제기\n",
      "{'page': 7.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.20110664}\n",
      "\n",
      "====================\n",
      "\n",
      "▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································13\n",
      "▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화····························································14\n",
      "3. 기술/연구\n",
      "▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표······························································15\n",
      "▹ 구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························16\n",
      "▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수 ···········································17\n",
      "4. 인력/교육\n",
      "▹ 영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아·······························18\n",
      "Ⅱ\n",
      ". 주요 행사\n",
      "▹CES 2024·····························································································································19\n",
      "▹AIMLA 2024·························································································································19\n",
      "▹AAAI Conference on Artificial Intelligence··································································19\n",
      "{'page': 1.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.19594887}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\"gpt-4o 미니 출시 관련 정보에 대해서 알려줘\")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화\n",
      "KEY Contents\n",
      "n 구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은\n",
      "구글과 클라우드 서비스 사용 계약도 체결\n",
      "n 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인\n",
      "앤스로픽 및 오픈AI와 협력을 확대하는 추세\n",
      "£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\n",
      "n 구글이 2023년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억\n",
      "달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\n",
      "∙ 구글은 2023년 2월 앤스로픽에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존도 지난 9월\n",
      "앤스로픽에 최대 40억 달러의 투자 계획을 공개\n",
      "∙ 한편, 2023년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해\n",
      "4년간 30억 달러 규모의 계약을 체결\n",
      "∙ 오픈AI 창업자 그룹의 일원이었던 다리오(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei)\n",
      "남매가 2021년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드(Claude)’ LLM을 개발\n",
      "n 아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈\n",
      "AI와 협력을 확대\n",
      "∙ 마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023년 1월 추가로 100억 달러를\n",
      "투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure)\n",
      "클라우드 플랫폼을 사용해 AI 모델을 훈련\n",
      "£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\n",
      "n 구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\n",
      "통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속\n",
      "{'page': 13.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.42183322}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽\", search_kwargs={\"alpha\": 1, \"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화\n",
      "KEY Contents\n",
      "n 구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은\n",
      "구글과 클라우드 서비스 사용 계약도 체결\n",
      "n 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인\n",
      "앤스로픽 및 오픈AI와 협력을 확대하는 추세\n",
      "£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\n",
      "n 구글이 2023년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억\n",
      "달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\n",
      "∙ 구글은 2023년 2월 앤스로픽에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존도 지난 9월\n",
      "앤스로픽에 최대 40억 달러의 투자 계획을 공개\n",
      "∙ 한편, 2023년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해\n",
      "4년간 30억 달러 규모의 계약을 체결\n",
      "∙ 오픈AI 창업자 그룹의 일원이었던 다리오(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei)\n",
      "남매가 2021년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드(Claude)’ LLM을 개발\n",
      "n 아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈\n",
      "AI와 협력을 확대\n",
      "∙ 마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023년 1월 추가로 100억 달러를\n",
      "투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure)\n",
      "클라우드 플랫폼을 사용해 AI 모델을 훈련\n",
      "£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\n",
      "n 구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\n",
      "통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속\n",
      "{'page': 13.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.7921144}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽\", search_kwargs={\"alpha\": 0, \"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동적 `search_kwargs` 사용\n",
    "- `filter`: metadata 필터링 적용\n",
    "\n",
    "(예시) `page` 가 5보다 작은 문서만 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023년 12월호\n",
      "Ⅰ\n",
      ". 인공지능 산업 동향 브리프\n",
      "1. 정책/법제\n",
      "▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ·························1\n",
      "▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의···························2\n",
      "▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언···························3\n",
      "▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각·····································4\n",
      "▹ 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출·················5\n",
      "▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항···················································6\n",
      "2. 기업/산업\n",
      "▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································7\n",
      "▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ·······································8\n",
      "▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································9\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12\n",
      "{'page': 1.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.1800869}\n",
      "\n",
      "====================\n",
      "\n",
      "2023년 12월호\n",
      "Ⅰ\n",
      ". 인공지능 산업 동향 브리프\n",
      "1. 정책/법제\n",
      "▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ·························1\n",
      "▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의···························2\n",
      "▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언···························3\n",
      "▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각·····································4\n",
      "▹ 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출·················5\n",
      "▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항···················································6\n",
      "2. 기업/산업\n",
      "▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································7\n",
      "▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ·······································8\n",
      "▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································9\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12\n",
      "{'page': 1.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'score': 0.18006735}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 claude 출시 관련 내용을 알려줘\",\n",
    "    search_kwargs={\"filter\": {\"page\": {\"$lt\": 5}}, \"k\": 2},\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동적 `search_kwargs` 사용\n",
    "- `filter`: metadata 필터링 적용\n",
    "\n",
    "(예시) `source` 가 `SPRi AI Brief_8월호_산업동향.pdf` 문서내 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 claude 3.5 출시 관련 내용을 알려줘\",\n",
    "    search_kwargs={\n",
    "        \"filter\": {\"source\": {\"$eq\": \"SPRi AI Brief_7월호_산업동향.pdf\"}},\n",
    "        \"k\": 3,\n",
    "    },\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking 적용\n",
    "\n",
    "아직은 `pre` 기능입니다.\n",
    "\n",
    "- 동적 reranking 기능을 구현해 놓았지만, pinecone 라이브러리 의존성에 문제가 있을 수 있습니다.\n",
    "- 따라서, 아래 코드는 향후 의존성 해결 후 원활하게 동작할 수 있습니다.\n",
    "\n",
    "참고 문서: https://docs.pinecone.io/guides/inference/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rerank_documents]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GRPCIndex' object has no attribute 'inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 실행 결과\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m search_results \u001b[38;5;241m=\u001b[39m \u001b[43mpinecone_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m앤스로픽의 클로드 소넷\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrerank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrerank_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbge-reranker-v2-m3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_n\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mpage_content)\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_core\\retrievers.py:253\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    252\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    256\u001b[0m         result,\n\u001b[0;32m    257\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_core\\retrievers.py:246\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 246\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:376\u001b[0m, in \u001b[0;36mPineconeKiwiHybridRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **search_kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# Rerank 옵션이 있는 경우 rerank 수행\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_kwargs\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrerank\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    375\u001b[0m ):\n\u001b[1;32m--> 376\u001b[0m     documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rerank_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_teddynote\\community\\pinecone.py:499\u001b[0m, in \u001b[0;36mPineconeKiwiHybridRetriever._rerank_documents\u001b[1;34m(self, query, documents, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m top_n \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_n\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(documents))\n\u001b[0;32m    495\u001b[0m rerank_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    496\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(i), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: doc\u001b[38;5;241m.\u001b[39mpage_content} \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents)\n\u001b[0;32m    497\u001b[0m ]\n\u001b[1;32m--> 499\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241m.\u001b[39mrerank(\n\u001b[0;32m    500\u001b[0m     model\u001b[38;5;241m=\u001b[39mrerank_model,\n\u001b[0;32m    501\u001b[0m     query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m    502\u001b[0m     documents\u001b[38;5;241m=\u001b[39mrerank_docs,\n\u001b[0;32m    503\u001b[0m     top_n\u001b[38;5;241m=\u001b[39mtop_n,\n\u001b[0;32m    504\u001b[0m     return_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    505\u001b[0m )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# 재정렬된 결과를 기반으로 문서 리스트 재구성\u001b[39;00m\n\u001b[0;32m    508\u001b[0m reranked_documents \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GRPCIndex' object has no attribute 'inference'"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 클로드 소넷\",\n",
    "    search_kwargs={\"rerank\": True, \"rerank_model\": \"bge-reranker-v2-m3\", \"top_n\": 3},\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-gLkynrUQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
