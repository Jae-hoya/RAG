{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프를 그리기 위한 라이브러리 설치\n",
    "# !pip install -qU grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(\n",
    "    [\n",
    "        \"재호는 랭체인 주식회사에서 근무를 하였습니다.\",\n",
    "        \"재호의 직업은 RAG개발자입니다.\",\n",
    "        \"진원의 직업은 음악치료사입니다.\",\n",
    "        \"재호는 로또 1등에 당첨되었습니다.\",\n",
    "        \"재호는 진원이와 곧 결혼합니다.\",\n",
    "    ],\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "template = \"\"\"\n",
    "Answer the questio based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\":retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'재호는 진원이와 결혼합니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"재호는 누구랑 결혼해?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 구성 확인\n",
    "`Runnable` 그래프를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'788da180c77c44b49bd27fdf083407d5': Node(id='788da180c77c44b49bd27fdf083407d5', name='Parallel<context,question>Input', data=<class 'pydantic.v1.main.RunnableParallel<context,question>Input'>, metadata=None),\n",
       " 'a2339931e22c4df7b9cd73ea1603227b': Node(id='a2339931e22c4df7b9cd73ea1603227b', name='Parallel<context,question>Output', data=<class 'pydantic.v1.main.RunnableParallel<context,question>Output'>, metadata=None),\n",
       " 'e01a63000f704b7d93298dacb66b3851': Node(id='e01a63000f704b7d93298dacb66b3851', name='VectorStoreRetriever', data=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001490FEBE950>), metadata=None),\n",
       " '465f0f3384924700a9a29e407128ee19': Node(id='465f0f3384924700a9a29e407128ee19', name='Passthrough', data=RunnablePassthrough(), metadata=None),\n",
       " '7e8573c4614f48f786e2ad8a4cbc586d': Node(id='7e8573c4614f48f786e2ad8a4cbc586d', name='ChatPromptTemplate', data=ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\\nAnswer the questio based only on the following context:\\n{context}\\n\\nQuestion:\\n{question}\\n'))]), metadata=None),\n",
       " '0d4f9712e5844ed3a7b6280abfd8cdfc': Node(id='0d4f9712e5844ed3a7b6280abfd8cdfc', name='ChatOpenAI', data=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000014910181B90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000014912A424D0>, root_client=<openai.OpenAI object at 0x0000014910CEBDD0>, root_async_client=<openai.AsyncOpenAI object at 0x0000014910DCBF10>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy=''), metadata=None),\n",
       " '93381f84c1f84a17a0743f26a30f81dd': Node(id='93381f84c1f84a17a0743f26a30f81dd', name='StrOutputParser', data=StrOutputParser(), metadata=None),\n",
       " 'eda33d4aa6834fb78f8359017dba246c': Node(id='eda33d4aa6834fb78f8359017dba246c', name='StrOutputParserOutput', data=<class 'pydantic.v1.main.StrOutputParserOutput'>, metadata=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인의 그래프에서 노드를 가져온다.\n",
    "chain.get_graph().nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Edge(source='2d24583c45044d028606fa73b74d8214', target='95ef06a0eaf34380aaac97b8137d070c', data=None, conditional=False),\n",
       " Edge(source='95ef06a0eaf34380aaac97b8137d070c', target='b8782630b9be49ca964c278f6794ac07', data=None, conditional=False),\n",
       " Edge(source='2d24583c45044d028606fa73b74d8214', target='acf0a90b535e4143a12c46a1a2b08ddc', data=None, conditional=False),\n",
       " Edge(source='acf0a90b535e4143a12c46a1a2b08ddc', target='b8782630b9be49ca964c278f6794ac07', data=None, conditional=False),\n",
       " Edge(source='b8782630b9be49ca964c278f6794ac07', target='89f9eff9efc04dcf80fa2da78abb53f8', data=None, conditional=False),\n",
       " Edge(source='89f9eff9efc04dcf80fa2da78abb53f8', target='aff983690f1b4d82bba86c376c009311', data=None, conditional=False),\n",
       " Edge(source='5fc2c7f050a84ecc8ee71b3b65432e06', target='3764998335404ca4bb12ab4ef510cf2f', data=None, conditional=False),\n",
       " Edge(source='aff983690f1b4d82bba86c376c009311', target='5fc2c7f050a84ecc8ee71b3b65432e06', data=None, conditional=False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인의 그래프에서 엣지를 가져온다\n",
    "chain.get_graph().edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프출력\n",
    "그래프를 출력하면 이해하기 쉬운 형태로 표현할 수 있다.\n",
    "\n",
    "`chain.get_graph().print_ascii()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +---------------------------------+         \n",
      "           | Parallel<context,question>Input |         \n",
      "           +---------------------------------+         \n",
      "                    **               **                \n",
      "                 ***                   ***             \n",
      "               **                         **           \n",
      "+----------------------+              +-------------+  \n",
      "| VectorStoreRetriever |              | Passthrough |  \n",
      "+----------------------+              +-------------+  \n",
      "                    **               **                \n",
      "                      ***         ***                  \n",
      "                         **     **                     \n",
      "           +----------------------------------+        \n",
      "           | Parallel<context,question>Output |        \n",
      "           +----------------------------------+        \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                  +--------------------+               \n",
      "                  | ChatPromptTemplate |               \n",
      "                  +--------------------+               \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                      +------------+                   \n",
      "                      | ChatOpenAI |                   \n",
      "                      +------------+                   \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                +-----------------------+              \n",
      "                | StrOutputParserOutput |              \n",
      "                +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프롬프트 가져오기\n",
    "`chain.get_prompts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\\nAnswer the questio based only on the following context:\\n{context}\\n\\nQuestion:\\n{question}\\n'))])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-gLkynrUQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
