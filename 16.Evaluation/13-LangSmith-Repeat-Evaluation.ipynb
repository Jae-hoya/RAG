{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 반복 평가\n",
    "\n",
    "실험에 반복을 추가할 수 있습니다.\n",
    "\n",
    "이는 평가를 여러 번 반복할 수 있게 하여 다음과 같은 경우에 유용합니다:\n",
    "\n",
    "- 더 큰 평가 세트의 경우\n",
    "- 가변적인 응답을 생성할 수 있는 체인의 경우\n",
    "- 가변적인 점수를 생성할 수 있는 평가(예: llm-as-judge)의 경우\n",
    "\n",
    "https://docs.smith.langchain.com/how_to_guides/evaluation/evaluate_llm_application#evaluate-on-a-dataset-with-repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH16-Evaluations\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH16-Evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myrag import PDFRAG\n",
    "\n",
    "\n",
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question_with_llm(llm):\n",
    "    # PDFRAG 객체 생성\n",
    "    rag = PDFRAG(\n",
    "        \"data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "        llm,\n",
    "    )\n",
    "\n",
    "    # 검색기(retriever) 생성\n",
    "    retriever = rag.create_retriever()\n",
    "\n",
    "    # 체인(chain) 생성\n",
    "    rag_chain = rag.create_chain(retriever)\n",
    "\n",
    "    def _ask_question(inputs: dict):\n",
    "        # 질문에 대한 컨텍스트 검색\n",
    "        context = retriever.invoke(inputs[\"question\"])\n",
    "        # 검색된 문서들을 하나의 문자열로 결합\n",
    "        context = \"\\n\".join([doc.page_content for doc in context])\n",
    "        # 질문, 컨텍스트, 답변을 포함한 딕셔너리 반환\n",
    "        return {\n",
    "            \"question\": inputs[\"question\"],\n",
    "            \"context\": context,\n",
    "            \"answer\": rag_chain.invoke(inputs[\"question\"]),\n",
    "        }\n",
    "\n",
    "    return _ask_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "gpt_chain = ask_question_with_llm(ChatOpenAI(model=\"gpt-4o-mini\", temperature=1.0))\n",
    "\n",
    "# Ollama 모델을 불러옵니다.\n",
    "ollama_chain = ask_question_with_llm(\n",
    "    ChatOllama(model=\"EEVE-Korean-10.8B:latest\", temperature=1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 모델을 활용한 RAG 에 대하여 반복 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'REPEAT_EVAL-d7266763' at:\n",
      "https://smith.langchain.com/o/2d0ce887-3f7f-59af-8d5e-12c1371ef5d5/datasets/334d943e-3086-4d03-91ae-4b5145224ffc/compare?selectedSessions=7546d053-dc69-4d80-9e26-87225ae62232\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2aab56710348caaf605bef25fb465b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 7b7528ca-8d2a-4f9a-a888-a31a941b85b0: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 64adf6c9-beaa-4d0d-a209-06d39a48de40: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run db8fb7d5-d1ec-44cb-9fec-42d2a988dfda: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 043466c1-21ac-4573-8c37-73adc58a5be1: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 813c6c87-7d41-4eea-b21c-82d54e913051: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 2ed6a746-e3a3-45c5-a3f2-fba7874f50fe: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run dd71a7e1-d952-44af-8983-d35cba1ab0d3: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run c2774432-ad54-4332-a93a-8f309923c1eb: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 6fabbfa8-d5f1-4d1f-8e94-ebc95bc7811f: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 531e43c3-f768-49a1-a798-1bd142b9333e: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 97078d70-619e-4425-8be5-c2b5962a294a: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 80fff97a-4e4e-4268-a262-e4812f3c78e5: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\2251587231.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExperimentResults REPEAT_EVAL-d7266763>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# qa 평가자 생성\n",
    "cot_qa_evalulator = LangChainStringEvaluator(\n",
    "    \"cot_qa\",\n",
    "    config={\"llm\": ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)},\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],\n",
    "        \"reference\": run.outputs[\"context\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "dataset_name = \"RAG_EVAL_DATASET_teddynote\"\n",
    "\n",
    "# 평가 실행\n",
    "evaluate(\n",
    "    gpt_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[cot_qa_evalulator],\n",
    "    experiment_prefix=\"REPEAT_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Repeat 평가를 수행합니다. GPT-4o-mini 모델 (cot_qa)\",\n",
    "    },\n",
    "    num_repetitions=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ollama 모델을 활용한 RAG 에 대하여 반복 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'REPEAT_EVAL-ee9360c0' at:\n",
      "https://smith.langchain.com/o/2d0ce887-3f7f-59af-8d5e-12c1371ef5d5/datasets/334d943e-3086-4d03-91ae-4b5145224ffc/compare?selectedSessions=a5b2a09f-6289-42aa-b40e-f897bbbd9076\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8cc8cd2acc446083f29c48de703d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running target function: 'question'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 73b3e8b4-2549-48fa-b5f0-a70935767938: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\486136241.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running target function: 'question'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run bcadfe54-89b0-4208-a616-145ce51cfe48: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\486136241.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 8a7b377a-d666-4901-be97-b8980cf515be: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\486136241.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator evaluate> on run 7a9d658c-49e4-4898-84c7-7f8c20a11e4b: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py\", line 258, in evaluate\n",
      "    else self._prepare_data(run, example)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\skyop\\AppData\\Local\\Temp\\ipykernel_7640\\486136241.py\", line 8, in <lambda>\n",
      "    \"prediction\": run.outputs[\"answer\"],\n",
      "                  ~~~~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# qa 평가자 생성\n",
    "cot_qa_evalulator = LangChainStringEvaluator(\n",
    "    \"cot_qa\",\n",
    "    config={\"llm\": ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)},\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],\n",
    "        \"reference\": run.outputs[\"context\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "dataset_name = \"RAG_EVAL_DATASET_teddynote\"\n",
    "\n",
    "# 평가 실행\n",
    "evaluate(\n",
    "    ollama_chain,\n",
    "    data=dataset_name,\n",
    "    evaluators=[cot_qa_evalulator],\n",
    "    experiment_prefix=\"REPEAT_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Repeat 평가를 수행합니다. EEVE-Korean-10.8B 모델 (cot_qa)\",\n",
    "    },\n",
    "    num_repetitions=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-gLkynrUQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
