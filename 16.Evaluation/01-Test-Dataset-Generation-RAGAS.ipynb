{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합성 테스트 데이터셋 생성\n",
    "\n",
    "- 합성테스트(Synthetic data)\n",
    "\n",
    "RAGAS를 쓰는이유? \n",
    "\n",
    "RAGAS에는 특별한 알고리즘이 있다. 문서가 있으면, 문서안에서 사용자가 잠정적으로 낼수있는 질문과 답변을 만들어낸다. seed data를 가지고 좋은질문과 나쁜질문을 판별을하고 그에대해서 답변한다. 여기서 qa샘플로 평가를한다.\n",
    "\n",
    " 문서를 주면 문서를 기반으로 질문과 답변을 만들어서(qa샘플을 만들어서) 우리의 질문과 얼마나 유사도가 높은지 평가를한다.\n",
    "\n",
    " **ragas의 요청사항**\n",
    " 각 문서 객체에는 `metadata`를 통해 액세스할 수 있는 문서에 대한 추가 정보를 저장하는데 사용할 수 있는 메타데이터 사전이 포함되어있다.\n",
    "\n",
    " 메타데이터 사전에는 `filename`이라는 키가 포함되어야 한다. 이 키는 Test datasets 생성 프로세스에 활용될 것 이므로, 메타데이터의 filename속성은 동일한 무서에 속한 청크를 식별하는데 도움이 된다.\n",
    "\n",
    " - RAGAS Dataset은 검수가 필수적이다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "loader = PDFPlumberLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# 목차, 끝페이지 제외. 이곳에서 질문을 만들면 인되기 때문. 이 문서를 ragas에 전달한다.\n",
    "docs = docs[3:-1]\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'page': 3,\n",
       " 'total_pages': 23,\n",
       " 'Author': 'dj',\n",
       " 'Creator': 'Hwp 2018 10.0.0.13462',\n",
       " 'Producer': 'Hancom PDF 1.3.0.542',\n",
       " 'CreationDate': \"D:20231208132838+09'00'\",\n",
       " 'ModDate': \"D:20231208132838+09'00'\",\n",
       " 'PDFVersion': '1.4'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터에 `filename`을 추가해주는 과정. filename을 추가하는데 source라는 metadata를 넣어준다.\n",
    "for doc in docs:\n",
    "    doc.metadata[\"filename\"] = doc.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'page': 3,\n",
       " 'total_pages': 23,\n",
       " 'Author': 'dj',\n",
       " 'Creator': 'Hwp 2018 10.0.0.13462',\n",
       " 'Producer': 'Hancom PDF 1.3.0.542',\n",
       " 'CreationDate': \"D:20231208132838+09'00'\",\n",
       " 'ModDate': \"D:20231208132838+09'00'\",\n",
       " 'PDFVersion': '1.4',\n",
       " 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context, conditional\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.extractor import KeyphraseExtractor\n",
    "from ragas.testset.docstore import InMemoryDocumentStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 데이터셋 생성기 : 이놈은 좋은걸 써주는게 좋음. local llm을 쓰면 질문 답변이 좋지않을수 있다.\n",
    "generator_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 데이터셋 비평기 : generator llm에서 질문을 만들어내면, 이 질문이 적합한지를 평가를한다.\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 문서 임베딩\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DocumentStore를 초기화 합니다. 사용자 정의 LLM과 임베딩을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "langchain_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "\n",
    "# 주요구문 추출기. 문서들이 있으면 중요한 단락을 추출한다.\n",
    "keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)\n",
    "\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "# InmemoryDocumentStore를 초기화한다.\n",
    "# 이는 문서를 메모리에저장하고 관리하는 저장소다.\n",
    "docstore = InMemoryDocumentStore(\n",
    "    splitter=splitter,\n",
    "    embeddings=ragas_embeddings,\n",
    "    extractor=keyphrase_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TestSet 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    ragas_embeddings,\n",
    "    docstore=docstore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**질문의 유형별 분포**\n",
    "- simple: 간단한 질문\n",
    "- reasoning: 추론이 필요한 질문\n",
    "- multi_context: 여러 맥락을 고려해야 하는 질문\n",
    "- conditional: 조건부 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 유형별 분포 결정\n",
    "# simple: 간단한 질문, reasoning: 추론이 필요한 질문, multi_context: 여러 맥락을 고려해야 하는 질문, conditional: 조건부 질문\n",
    "distributions = {simple: 0.4, reasoning: 0.2, multi_context: 0.2, conditional: 0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- documents: 문서 데이터\n",
    "- test_size: 생성할 질문의 수\n",
    "- distributions: 질문 유형별 분포\n",
    "- with_debugging_logs: 디버깅 로그 출력 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0260c6c4f3ed416aa7f8fef370e95f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb23d2d36a4b4b6db28de5d3061d6c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AGI', 'Artificial Intelligence', 'Operationalizing Progress', 'Levels of AGI', 'Good Old Fashioned Artificial Intelligence (GOFAI)']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AGI', 'Artificial Intelligence', 'Operationalizing Progress', 'Levels of AGI', 'Good Old Fashioned Artificial Intelligence (GOFAI)']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Safety Summit', 'AI governance', 'AI risk management', 'AI policy recommendations', 'AI development guidelines']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['CTA Conference', 'CES 2024', 'AIMLA 2024', 'AAAI Conference', 'Artificial Intelligence']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI innovation', 'Responsible AI', 'Data privacy', 'Content moderation', 'User safety']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Cohere', 'Data Provenance Explorer', 'Data transparency crisis', 'Data integrity', 'Data management']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Cohere', 'Data Provenance Explorer', 'Data transparency crisis', 'Data integrity', 'Data management']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Safety Institute', 'AI governance', 'AI risk management', 'AI development guidelines', 'AI safety measures']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI technology', 'Computers usage', 'GatesNotes', 'Change in computing', 'Future of AI']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['CTA Conference', 'CES 2024', 'AIMLA 2024', 'AAAI Conference', 'Artificial Intelligence']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the different levels of artificial intelligence as described in the context?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of data integrity in ensuring data transparency?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What role does content moderation play in the context of AI development?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What does 'Operationalizing Progress' refer to in the context of AGI development?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What insights does GatesNotes provide about the impact of AI on computer usage?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of the data transparency crisis mentioned in the context?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the focus of AIMLA 2024?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What was the purpose of the AI Safety Summit held in November 2023?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key components of AI safety measures discussed in the context?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are some key events related to Artificial Intelligence scheduled for 2024?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the role of content moderation in AI development, which is a clear and specific inquiry. It does not rely on external references or context, making it independent and understandable. The intent is clear, as it seeks to explore the significance and impact of content moderation within the realm of AI. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the purpose of the AI Safety Summit held in November 2023. It is specific and clear in its intent, seeking information about a particular event and its objectives. The question is independent as it does not rely on external references or additional context to be understood. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the meaning of 'Operationalizing Progress' specifically in the context of AGI (Artificial General Intelligence) development. It is clear in its intent, as it seeks a definition or explanation of a specific term within a defined field. The question is independent and does not rely on external references, making it understandable and answerable based on the details provided. Therefore, it meets the criteria for clarity and answerability.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of a 'data transparency crisis' but refers to 'the context' without providing any specific details about what that context entails. This reliance on unspecified external information makes the question unclear and difficult to answer for someone who does not have access to the mentioned context. To improve clarity and answerability, the question could specify what the data transparency crisis involves, such as its causes, implications, or examples, thereby allowing for a more focused and relevant response.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the different levels of artificial intelligence as described in 'the context', but it does not provide any specific details or definitions of what 'the context' refers to. This reliance on unspecified external information makes the question unclear and unanswerable for someone who does not have access to that context. To improve clarity and answerability, the question should either include a brief description of the levels of artificial intelligence or specify the source or framework from which these levels are derived. Alternatively, it could be rephrased to ask for a general overview of the levels of artificial intelligence without referencing external context.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the significance of data integrity in relation to data transparency. It is clear in its intent, as it seeks to understand the relationship between these two concepts. The question is independent and does not rely on external references or specific documents, making it self-contained. However, it could be improved by specifying the context in which data integrity and transparency are being considered (e.g., in a specific industry, type of data, or regulatory framework). This would help narrow down the focus and provide a more targeted answer.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the significance of data integrity in ensuring data transparency?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for insights from GatesNotes regarding the impact of AI on computer usage. It is specific in its focus on GatesNotes and the topic of AI's impact on computer usage, making the intent clear. However, it assumes familiarity with GatesNotes and its content without providing any context or details about what specific insights are being sought. To improve clarity and answerability, the question could specify whether it is looking for recent articles, particular themes, or types of insights (e.g., statistical data, expert opinions) related to AI's impact on computer usage.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the focus of AIMLA 2024, which is a specific event or conference. However, it lacks clarity because it does not specify what aspect of AIMLA 2024 is of interest (e.g., themes, topics, speakers, or objectives). To improve clarity and answerability, the question could be reframed to specify whether the inquiry is about the overall theme, specific sessions, or the goals of the event. For example, it could be rephrased as 'What are the main themes and topics of discussion at AIMLA 2024?' or 'What are the objectives of AIMLA 2024?'.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for key events related to Artificial Intelligence scheduled for 2024. It is specific in its focus on events and the year, making it clear what type of information is being sought. However, the term 'key events' could be interpreted in various ways, such as conferences, releases, or milestones, which introduces a slight ambiguity. To improve clarity, the question could specify the type of events of interest (e.g., conferences, workshops, product launches) or the geographical focus (e.g., global, regional).\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What are some key events related to Artificial Intelligence scheduled for 2024?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key components of AI safety measures but refers to 'the context' without providing any specific details or information about what that context entails. This reliance on unspecified external information makes the question unclear and difficult to answer for someone who does not have access to that context. To improve clarity and answerability, the question could specify what context is being referred to (e.g., a particular study, framework, or set of guidelines) or provide a brief overview of the relevant aspects of AI safety measures that are of interest.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the causes and implications of the data transparency crisis discussed in the SPRi AI Brief?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the different levels of artificial intelligence as outlined in the document discussing the application of AI and AGI?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What role does maintaining data integrity play in fostering transparency within data provenance frameworks?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the main themes and topics of discussion at AIMLA 2024?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Content moderation plays a crucial role in AI development by ensuring that the AI systems are trained on appropriate data and that harmful or inappropriate content is filtered out. This helps in maintaining the integrity and safety of AI applications.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What recent articles or themes does GatesNotes discuss regarding the impact of AI on computer usage, and what specific insights, such as statistical data or expert opinions, are provided?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"The purpose of the AI Safety Summit held in November 2023 was to discuss 28 key contents related to AI safety, focusing on AI's role in various sectors and addressing issues such as governance, safety, and the implications of AI technology.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What significant AI-related gatherings or milestones are anticipated in 2024 that highlight the economic implications of AI skills?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"The term 'Operationalizing Progress' in the context of AGI development refers to the process of implementing and applying advancements in AGI capabilities, ensuring that these developments are effectively integrated into practical applications and systems.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key components of AI safety measures discussed in the document titled 'Our approach to responsible AI innovation'?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the different levels of artificial intelligence as outlined in a specific document, which is not provided within the question itself. This reliance on an unspecified document makes the question unclear and not fully independent, as it assumes access to that document for a complete understanding. To improve clarity and answerability, the question could be reframed to ask for a general overview of the levels of artificial intelligence without referencing a specific document, or it could include a brief summary of the document's content to provide context.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of maintaining data integrity in promoting transparency within data provenance frameworks. It is specific and has a clear intent, focusing on the relationship between data integrity and transparency in a defined context (data provenance frameworks). However, the question could be improved by providing a brief definition or context for 'data provenance frameworks' to ensure that all readers understand the term. This would enhance clarity and answerability for those who may not be familiar with the concept.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the causes and implications of the data transparency crisis as discussed in the SPRi AI Brief. While it specifies the topic of interest (data transparency crisis) and the source (SPRi AI Brief), it assumes familiarity with this specific document without providing any context or details about its content. This reliance on an external reference makes the question less clear and answerable for those who may not have access to or knowledge of the SPRi AI Brief. To improve clarity and answerability, the question could include a brief summary of the key points or findings from the SPRi AI Brief regarding the data transparency crisis, or it could be reframed to ask about general causes and implications of data transparency issues without referencing a specific document.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the main themes and topics of discussion at AIMLA 2024. It is clear in its intent, seeking specific information about the event. However, it may be challenging to answer without additional context or access to the agenda or program of AIMLA 2024, which is not provided in the question. To improve clarity and answerability, the question could specify whether it is looking for themes related to a particular field (e.g., artificial intelligence, machine learning) or if it is interested in a summary of the event's focus areas. Additionally, including a request for information on notable speakers or sessions could enhance the specificity of the inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How does data integrity support transparency in provenance?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key components of AI safety measures as discussed in a specific document titled 'Our approach to responsible AI innovation'. While it specifies the topic of interest (AI safety measures) and the document, it relies on access to this document for a complete understanding, which makes it unclear for those who do not have it. To improve clarity and answerability, the question could be reframed to ask for general key components of AI safety measures without referencing a specific document, or it could summarize the main points of the document within the question itself.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['FTC', 'AI regulation', 'Copyright Office', 'Notice of Inquiry', 'AI content creation']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about significant AI-related gatherings or milestones anticipated in 2024, specifically focusing on their economic implications related to AI skills. It is clear in its intent and specifies the year (2024) and the type of events (gatherings or milestones) of interest. However, the phrase 'economic implications of AI skills' could be interpreted in various ways, which may introduce some ambiguity. To improve clarity, the question could specify what aspects of economic implications are of interest (e.g., job market impact, investment opportunities, skill development trends) or provide examples of the types of gatherings or milestones being referred to.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about recent articles or themes discussed on GatesNotes regarding the impact of AI on computer usage, specifically seeking insights like statistical data or expert opinions. While it is clear in its intent to gather information about AI's impact and the type of insights desired, it assumes familiarity with GatesNotes and its content without providing any context or details about the articles or themes. To improve clarity and answerability, the question could specify a time frame for the articles (e.g., 'in the last year') or provide a brief description of the types of insights being sought. Additionally, it could clarify whether the focus is on specific articles or a general overview of themes.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI development', '20th century technology', 'Dario Amodei', 'Claude LLM', 'AI applications']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['G7 AI Framework', 'International Code of Conduct for Advanced AI Systems', 'AI Governance', 'AI Development Guidelines', 'AI Global Cooperation']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key aspects of AI regulation discussed in the context?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What key AI events in 2024 will showcase the economic impact of AI skills?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AGI (Artificial General Intelligence)', 'AI applications', 'Key contents', 'AI model development', '2023 advancements in AGI']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the significance of Claude LLM in the context of AI development?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions explore the relationship between data integrity and transparency, focusing on similar concepts but with different phrasing. However, the second question narrows the focus to 'provenance', which may imply a different depth of inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI innovation', 'Responsible AI', 'Data privacy', 'Content moderation', 'User safety']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key aspects of the AI Development Guidelines established by the G7?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key aspects of AI applications mentioned in the context?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key considerations for responsible AI innovation?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question asks for key events related to Artificial Intelligence in 2024, while the second question specifically focuses on events that showcase the economic impact of AI skills. This indicates a difference in constraints and depth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the 'key aspects of AI regulation' but refers to 'the context' without providing any specific details about what that context entails. This reliance on unspecified external information makes the question unclear and difficult to answer for someone who does not have access to the mentioned context. To improve clarity and answerability, the question could specify what context is being referred to (e.g., a particular document, a recent event, or a specific regulatory framework) or provide a brief overview of the aspects of AI regulation that are of interest.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the key aspects of the AI Development Guidelines established by the G7, which is clear and specific. It does not rely on external references or context, making it independent and understandable. The intent is clear, as it seeks a summary of important points regarding the guidelines. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the key considerations for responsible AI innovation, which is a clear and specific inquiry. It does not rely on external references or context, making it independent and understandable. The intent is clear, as it seeks to identify important factors or principles related to responsible AI practices. Therefore, the question meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"What are the key considerations for responsible AI innovation?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the 'key aspects of AI applications' but refers to 'the context' without providing any specific details about what that context entails. This reliance on unspecified external information makes the question unclear and unanswerable for those who do not have access to the context being referenced. To improve clarity and answerability, the question could specify what context is being referred to (e.g., a particular study, report, or application area) or could directly list some aspects of AI applications that the question is interested in exploring.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key aspects of AI regulation discussed in the article about the FTC's recent actions regarding AI and copyright issues?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of Claude LLM in the context of AI development, which is a clear and specific inquiry. It identifies a particular subject (Claude LLM) and seeks to understand its importance within a broader field (AI development). However, the term 'significance' could be interpreted in various ways (e.g., technological impact, influence on research, commercial applications), which may lead to ambiguity in the type of response expected. To enhance clarity and answerability, the question could specify what aspect of significance is of interest, such as its contributions to model performance, ethical considerations, or advancements in natural language processing.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What is the significance of Claude LLM in the context of AI development?\"\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key aspects of AI applications discussed in the report on AI Safety and its implications for artificial intelligence?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The key AI events in 2024 that will showcase the economic impact of AI skills include CES 2024, which will feature various AI technologies and innovations, and AIMLA 2024, focusing on AI applications and their economic implications. Additionally, the AAAI Conference will discuss advancements in AI and its economic relevance.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The key aspects of the AI Development Guidelines established by the G7 include the establishment of an international code of conduct for advanced AI systems, the promotion of responsible AI development, and the emphasis on safety and ethical considerations in AI deployment. The guidelines also focus on the importance of transparency, accountability, and collaboration among nations in the development and regulation of AI technologies.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key aspects of AI regulation as discussed in an article regarding the FTC's recent actions related to AI and copyright issues. While it specifies the topic (AI regulation) and the context (FTC's actions), it relies on an unspecified article for its content, making it unclear for those who do not have access to that article. To improve clarity and answerability, the question could either summarize the main points of the article or specify the key aspects of AI regulation that are of interest, allowing for a more focused response without needing to reference external material.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the factors to prioritize for responsible AI innovation in the context of ethical implications during development. It is clear in its intent, focusing on responsible AI and ethical considerations. However, the question could be improved by specifying what types of ethical implications are being referred to (e.g., bias, privacy, accountability) or by providing examples of the factors that might be considered. This would help to narrow down the scope and make it easier to provide a focused answer. Overall, while the question is understandable, adding more detail would enhance its clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key aspects of AI applications as discussed in a report on AI Safety, indicating a specific topic of interest. However, it refers to 'the report' without providing any details about its content or context, which makes it unclear for those who do not have access to or knowledge of this specific report. To improve clarity and answerability, the question could specify the main themes or sections of the report that are of interest, or provide a brief summary of the report's focus. This would help in understanding what specific aspects of AI applications the question is targeting.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"What factors should be prioritized for responsible AI innovation if ethical implications arise during development?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['LLM Hallucination Index', 'GPT-4', 'Retrieval-Augmented Generation (RAG)', 'AI performance evaluation', 'Galileo']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the connections between the development of Claude LLM and its impact on AI advancements. While it is somewhat clear in its intent to explore the relationship between the model's development and broader AI progress, it lacks specificity regarding what aspects of 'development' and 'impact' are of interest. Additionally, the term 'Claude LLM' may not be universally recognized, which could lead to confusion. To improve clarity and answerability, the question could specify particular features of Claude LLM that are relevant to its development or define what types of AI advancements are being considered (e.g., in natural language processing, machine learning techniques, etc.).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What significant event related to LLMs occurred on November 15, 2023, involving Galileo?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions address the ethical aspects of AI innovation, but 'key considerations' suggests a broader and more comprehensive inquiry than 'factors that matter', which may imply a narrower focus.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What specific features of Claude LLM's development have contributed to advancements in natural language processing and other areas of artificial intelligence?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is specific and clear, asking about a significant event related to large language models (LLMs) that occurred on a specific date (November 15, 2023) and involves a particular entity (Galileo). It does not rely on external references or additional context, making it independent and understandable. The intent is clear, as it seeks information about a specific event. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"What significant event related to LLMs occurred on November 15, 2023, involving Galileo?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The context discusses various factors that matter for ethical AI innovation, including the need for responsible practices in AI development, the importance of transparency, and the necessity of addressing biases in AI systems. It emphasizes the significance of ethical considerations in the design and deployment of AI technologies.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Safety Institute', 'AI governance', 'AI risk management', 'AI development guidelines', 'AI safety measures']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the specific features of Claude LLM's development that have contributed to advancements in natural language processing and other areas of artificial intelligence. It is clear in its intent, specifying the subject (Claude LLM) and the areas of impact (natural language processing and artificial intelligence). However, the term 'specific features' could be interpreted in various ways, such as architectural innovations, training methodologies, or application scenarios. To enhance clarity and answerability, the question could specify which type of features are of interest (e.g., technical features, performance metrics, or use cases) or provide examples of the advancements being referred to.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key components of the AI development guidelines mentioned in the context?\"\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What specific features of Claude LLM's development have contributed to advancements in natural language processing and other areas of artificial intelligence?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the significance of Claude LLM in AI development, while the second question emphasizes specific features that have advanced NLP and AI. This leads to different depths and breadths of inquiry, as one is more general and the other is more specific.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the 'key components of the AI development guidelines' but refers to 'the context' without providing any specific details about what that context entails. This reliance on unspecified external information makes the question unclear and unanswerable for those who do not have access to the mentioned context. To improve clarity and answerability, the question should either include a brief description of the AI development guidelines or specify the context in which these guidelines are mentioned. Additionally, it could clarify what is meant by 'key components' to guide the response more effectively.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about a specific development related to LLMs on a particular date (November 15, 2023) and references Galileo's findings in relation to the LLM Hallucination Index. While it specifies a date and a topic, it is somewhat unclear because it assumes knowledge of both the 'key development' and the 'LLM Hallucination Index' without providing context or details about what these entail. Additionally, the phrasing suggests a causal relationship that may not be universally understood. To improve clarity and answerability, the question could specify what the 'key development' is or provide a brief explanation of the LLM Hallucination Index and how it relates to Galileo's findings. This would help ensure that the question is self-contained and comprehensible to a wider audience.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key components of the AI development guidelines outlined in the document discussing responsible AI innovation?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What significant development regarding large language models (LLMs) occurred on November 15, 2023, in relation to the findings from Galileo that impacted the LLM Hallucination Index, which measures the accuracy of AI-generated content?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key components of AI development guidelines as outlined in a specific document regarding responsible AI innovation. However, it references 'the document' without providing any details or context about it, making it unclear for those who do not have access to or knowledge of this document. To improve clarity and answerability, the question could specify the main themes or topics covered in the document or summarize its contents briefly. Alternatively, it could ask for general principles of responsible AI innovation without relying on a specific document.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 2, 'relevance': 2, 'score': 1.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\"LLM 'Tongyi Qianwen 2.0'\", 'AI model performance', 'MMLU benchmark', 'API capabilities', 'Generative AI advancements']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and seeks information about a significant development related to large language models (LLMs) that occurred on a specific date (November 15, 2023). It clearly states the context (findings from Galileo) and the specific aspect of interest (impact on the LLM Hallucination Index). However, the question assumes familiarity with the 'Galileo' findings and the 'LLM Hallucination Index' without providing any context or explanation about these terms. To improve clarity and answerability, the question could briefly define what the 'Galileo' findings are and explain the significance of the 'LLM Hallucination Index' in relation to LLMs. This would make the question more accessible to those who may not have prior knowledge of these concepts.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key features and advancements of LLM 'Tongyi Qianwen 2.0'?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI usage guidelines', 'National Artificial Intelligence Research Resource', 'Executive Order on AI development', 'Safe and trustworthy AI', 'AI application in education']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the purpose of the Executive Order on AI development issued by the White House?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the key features and advancements of the LLM 'Tongyi Qianwen 2.0'. It is specific in its focus on a particular model and seeks information about its features and advancements, which conveys a clear intent. However, the question could be improved by providing a bit more context about what aspects of the features and advancements are of interest (e.g., technical specifications, performance improvements, applications). This would help in tailoring the response more effectively. Overall, the question is understandable and answerable based on the details provided.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: \"What are the key features and advancements of LLM 'Tongyi Qianwen 2.0'?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the purpose of a specific Executive Order on AI development issued by the White House. It is clear in its intent, specifying the subject (Executive Order on AI development) and the entity responsible (the White House). However, the question could benefit from additional context, such as the date of the order or specific aspects of AI development it addresses, to enhance clarity and answerability. Nonetheless, it is generally understandable and can be answered based on existing knowledge of recent executive orders related to AI.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"What is the purpose of the Executive Order on AI development issued by the White House?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the advancements in AI showcased by Tongyi Qianwen 2.0 compared to its predecessor, which is clear in its intent and specifies the subject of interest (Tongyi Qianwen 2.0 and its predecessor). However, it could benefit from additional context regarding what specific aspects of AI advancements are of interest (e.g., performance improvements, new features, applications). This would help narrow down the focus and make the question more answerable. Overall, the question is relatively clear but could be improved by specifying the type of advancements being inquired about.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: \"What advancements in AI does Tongyi Qianwen 2.0 showcase compared to its predecessor?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the objectives of the White House's Executive Order on AI development, specifically focusing on what aims it seeks to achieve if implemented effectively. It is clear in its intent and specifies the subject matter (the Executive Order on AI development), making it understandable. However, the question assumes familiarity with the Executive Order itself, which may not be accessible to all audiences. To improve clarity and answerability, the question could briefly outline the key components or themes of the Executive Order, or specify the context in which these objectives are to be evaluated (e.g., economic impact, ethical considerations).\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"What objectives does the White House's Executive Order on AI development aim to achieve if implemented effectively?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions inquire about the advancements of LLM 'Tongyi Qianwen 2.0', but the first question focuses on key features while the second emphasizes improvements over the previous version, indicating a difference in depth and breadth of inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the objectives and intentions behind the Executive Order on AI development issued by the White House, maintaining the same depth and breadth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI applications', 'Data analysis', 'Machine learning', 'Performance metrics', 'AI technology trends']\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Tongyi Qianwen 2.0 has improvements over the previous version, including enhanced performance in various benchmarks such as MMLU, GSM8k, and ARC-C. It also features advancements in the ability to handle complex tasks and provides better API capabilities.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key aspects of AI applications mentioned in the context?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the 'key aspects of AI applications' but refers to 'the context' without providing any specific details about what that context entails. This reliance on unspecified external information makes the question unclear and unanswerable for those who do not have access to the context being referenced. To improve clarity and answerability, the question should either include a brief description of the context or specify the particular aspects of AI applications that are of interest (e.g., ethical considerations, technological advancements, industry applications).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key aspects of AI applications discussed in the IDC report on artificial intelligence software revenue forecasts?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the key aspects of AI applications as discussed in the IDC report on artificial intelligence software revenue forecasts. While it specifies the topic (AI applications) and the source (IDC report), it assumes familiarity with the report's content without providing any details or context. This reliance on an external document makes the question less independent and potentially unclear for those who do not have access to the report. To improve clarity and answerability, the question could specify which aspects of AI applications are of interest (e.g., trends, challenges, market segments) or provide a brief summary of the report's findings to frame the inquiry more effectively.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['SPRi AI Brief', 'AI application', 'AI trends', 'AI technology', 'AI development']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What are the key considerations for the application of AI in various fields?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the key considerations for applying AI across various fields, which is a broad and somewhat vague inquiry. While it does specify the topic of interest (AI applications), it does not clarify which fields are being referred to or what specific aspects of AI application are of concern (e.g., ethical considerations, technical challenges, regulatory issues). To improve clarity and answerability, the question could specify particular fields (e.g., healthcare, finance, education) or types of considerations (e.g., ethical, technical, economic) that the respondent should focus on.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What are the key ethical and technical considerations for the application of AI in healthcare, finance, and education?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for key ethical and technical considerations regarding the application of AI in three distinct fields: healthcare, finance, and education. It is clear in its intent to gather information on both ethical and technical aspects across these sectors. However, the question is somewhat broad, as it does not specify which particular ethical or technical considerations are of interest, nor does it provide context for the application of AI in these fields. To improve clarity and answerability, the question could be reframed to focus on specific ethical dilemmas (e.g., privacy concerns, bias) or technical challenges (e.g., data security, algorithm transparency) within each sector, or it could ask for a comparison of these considerations across the three fields.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 4 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI foundation models', 'Mandatory self-regulation', 'AI governance', 'AI policy discussions', \"EU's AI Act negotiations\"]\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What challenges are currently affecting the EU's AI Act negotiations regarding foundation models?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the challenges affecting the EU's AI Act negotiations specifically related to foundation models. It is clear in its intent, specifying the topic (EU's AI Act negotiations) and the focus area (foundation models). However, the question assumes a certain level of familiarity with the EU's AI Act and the ongoing negotiations, which may not be universally understood. To enhance clarity and answerability, it could be beneficial to provide a brief context about the EU's AI Act or specify the types of challenges being referred to (e.g., legal, technical, ethical).\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] simple question generated: \"What challenges are currently affecting the EU's AI Act negotiations regarding foundation models?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question is specific and seeks to understand the challenges in the EU's AI Act negotiations, particularly focusing on the prioritization of foundation models over other AI applications. It is clear in its intent and does not rely on external references, making it understandable and answerable based on the details provided. However, to enhance clarity, the question could specify what types of challenges are being referred to (e.g., legal, ethical, technical) or provide a brief context about the EU's AI Act for those unfamiliar with it. Overall, it meets the criteria for clarity and answerability.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ConditionalEvolution] question compressed: \"What specific challenges arise in the EU's AI Act negotiations if foundation models are prioritized over other AI applications?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions address challenges related to the EU's AI Act and foundation models, but they differ in focus. The first question emphasizes current challenges in negotiations, while the second implies a conditional scenario where foundation models take priority, leading to different depths of inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"The challenges that arise in the EU's AI Act if foundation models take priority include the need for mandatory self-regulation for foundation models, the potential for increased complexity in the regulatory framework, and the necessity to ensure that AI systems are developed and used responsibly while addressing the specific risks associated with foundation models.\", 'verdict': 1}\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋 생성\n",
    "# docs: 문서 데이터, 10: 생성할 질문의 수, distributions: 질문 유형별 분포, with_debugging_logs: 디버깅 로그 출력 여부\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents=docs, test_size=10, distributions=distributions, with_debugging_logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What role does content moderation play in the ...</td>\n",
       "      <td>[£유튜브, 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn...</td>\n",
       "      <td>Content moderation plays a crucial role in AI ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key aspects of the AI Development...</td>\n",
       "      <td>[SPRi AI Brief |\\n2023-12월호\\nG7, 히로시마 AI 프로세스를...</td>\n",
       "      <td>The key aspects of the AI Development Guidelin...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the purpose of the AI Safety Summit h...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n영국 AI 안전...</td>\n",
       "      <td>The purpose of the AI Safety Summit held in No...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does 'Operationalizing Progress' refer to...</td>\n",
       "      <td>[구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표\\nKEY C...</td>\n",
       "      <td>The term 'Operationalizing Progress' in the co...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What improvements does Tongyi Qianwen 2.0 have...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n알리바바 클라우...</td>\n",
       "      <td>Tongyi Qianwen 2.0 has improvements over the p...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What features of Claude LLM have advanced NLP ...</td>\n",
       "      <td>[저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRe...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does data integrity support transparency i...</td>\n",
       "      <td>[SPRi AI Brief |\\n2023-12월호\\n코히어, 데이터 투명성 확보를 ...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What key AI events in 2024 will showcase the e...</td>\n",
       "      <td>[Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CT...</td>\n",
       "      <td>The key AI events in 2024 that will showcase t...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What challenges come up in the EU's AI Act if ...</td>\n",
       "      <td>[∙ 3개국은 기반모델 전반에 대한 규제가 기술 중립적이고 위험 기반의 AI 규제 ...</td>\n",
       "      <td>The challenges that arise in the EU's AI Act i...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What factors matter for ethical AI innovation?</td>\n",
       "      <td>[£유튜브, 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn...</td>\n",
       "      <td>The context discusses various factors that mat...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ... episode_done\n",
       "0  What role does content moderation play in the ...  ...         True\n",
       "1  What are the key aspects of the AI Development...  ...         True\n",
       "2  What was the purpose of the AI Safety Summit h...  ...         True\n",
       "3  What does 'Operationalizing Progress' refer to...  ...         True\n",
       "4  What improvements does Tongyi Qianwen 2.0 have...  ...         True\n",
       "5  What features of Claude LLM have advanced NLP ...  ...         True\n",
       "6  How does data integrity support transparency i...  ...         True\n",
       "7  What key AI events in 2024 will showcase the e...  ...         True\n",
       "8  What challenges come up in the EU's AI Act if ...  ...         True\n",
       "9     What factors matter for ethical AI innovation?  ...         True\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 테스트셋을 pandas DataFrame으로 변환\n",
    "test_df = testset.to_pandas()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What role does content moderation play in the ...</td>\n",
       "      <td>[£유튜브, 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn...</td>\n",
       "      <td>Content moderation plays a crucial role in AI ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key aspects of the AI Development...</td>\n",
       "      <td>[SPRi AI Brief |\\n2023-12월호\\nG7, 히로시마 AI 프로세스를...</td>\n",
       "      <td>The key aspects of the AI Development Guidelin...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the purpose of the AI Safety Summit h...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n영국 AI 안전...</td>\n",
       "      <td>The purpose of the AI Safety Summit held in No...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does 'Operationalizing Progress' refer to...</td>\n",
       "      <td>[구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표\\nKEY C...</td>\n",
       "      <td>The term 'Operationalizing Progress' in the co...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What improvements does Tongyi Qianwen 2.0 have...</td>\n",
       "      <td>[1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n알리바바 클라우...</td>\n",
       "      <td>Tongyi Qianwen 2.0 has improvements over the p...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  ... episode_done\n",
       "0  What role does content moderation play in the ...  ...         True\n",
       "1  What are the key aspects of the AI Development...  ...         True\n",
       "2  What was the purpose of the AI Safety Summit h...  ...         True\n",
       "3  What does 'Operationalizing Progress' refer to...  ...         True\n",
       "4  What improvements does Tongyi Qianwen 2.0 have...  ...         True\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame의 상위 5개 행 출력\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame을 CSV 파일로 저장\n",
    "test_df.to_csv(\"data/ragas_synthetic_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-gLkynrUQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
