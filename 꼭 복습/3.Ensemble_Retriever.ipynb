{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# 시멘팅청커\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = [\n",
    "    PyPDFLoader(\"data/RAG/Adaptive_RAG.pdf\"),\n",
    "    PyPDFLoader(\"data/RAG/Naive_RAG.pdf\"),\n",
    "    PyPDFLoader(\"data/RAG/RAPTOR_RAG.pdf\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = []\n",
    "for loader in loader:\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitters = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = text_splitters.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # multi-lingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = FAISS.from_documents(documents, embeddings)\n",
    "faiss_retriever = faiss_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weight={0.4, 0.6}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='RetrievalComplex Query: \\nWhat currency is in \\nBilly Giles’ birthplace?Simple Query: \\nWhen is the birthday \\nof Michael F. Phelps?Documents\\nAnswer\\nDocuments\\nAnswer\\n(A) Single -Step Approach\\nInaccurate\\nRetrieval\\nRetrievalSimple Query: \\nWhen is the birthday \\nof Michael F. Phelps?Documents\\n(Intermediate) \\nAnswers\\n(B) Multi -Step Approach\\nInefficient\\nk times\\nComplex Query: \\nWhat currency is in \\nBilly Giles’ birthplace?Documents\\n(Intermediate) \\nAnswers\\nk timesStraightforward Query:' metadata={'source': 'data/RAG/Adaptive_RAG.pdf', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_retriever.invoke(\"What is Raptor RAG?\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowen J. Tyler, Jr. Ajor, Co-Tan’s sister, is excited about the possibility of going\n",
      "to Tom’s country to see strange and wonderful things...\n",
      "The hallucination here is that the summary states that Jr. Ajor and Co-Tan are sisters, but does not\n",
      "explicitly mention or imply this.\n",
      "Upon reviewing all parent nodes, we found that hallucinations did not propagate to higher layers.\n",
      "Generally, the hallucinations were minor and did not alter the thematic interpretation of the text.\n",
      "E.3 I MPACT ON QA T ASKS\n",
      "Question Answering:\n",
      "Question QueryThe\tmiddle\tear\tincludes\n",
      "the\ttympanic\tcavity\tand\n",
      "the\tthree\tossicles.\t\t (y)\n",
      "Question Answering:\n",
      "Answer GenerationRetriever pη\n",
      "(Non-Parametric)\n",
      "z 4\n",
      "z3\n",
      "z2\n",
      "z 1d(z)\n",
      "Jeopardy Question\n",
      "Generation:\n",
      "Answer QueryFigure 1: Overview of our approach. We combine a pre-trained retriever ( Query Encoder +Document\n",
      "Index ) with a pre-trained seq2seq model ( Generator ) and ﬁne-tune end-to-end. For query x, we use\n",
      "Published as a conference paper at ICLR 2024\n",
      "Example:\n",
      "Text of the child nodes:\n",
      "”And you will come with me to my people? We may live here among them, and\n",
      "you will be a great warrior–oh, when Jor dies you may even be chief, for there is\n",
      "none so mighty as my warrior...”But your father will not permit it–Jor, my father,\n",
      "High Chief of the Galus, will not permit it, for like me you are cos-ata-lo. Oh, Co-\n",
      "Tan, if we but could!... Bradley noticed that she spoke in English–broken English\n",
      "Ye Liu, Kazuma Hashimoto, Yingbo Zhou, Semih Yavuz, Caiming Xiong, and Philip Yu. Dense\n",
      "hierarchical retrieval for open-domain question answering. In Marie-Francine Moens, Xuanjing\n",
      "Huang, Lucia Specia, and Scott Wen-tau Yih (eds.), Findings of the Association for Compu-\n",
      "tational Linguistics: EMNLP 2021 , pp. 188–200, Punta Cana, Dominican Republic, Novem-\n",
      "ber 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.findings-emnlp.19.\n",
      "Training Strategy The remaining step is to train\n",
      "the smaller Language Model for Classifier , to\n",
      "accurately predict its complexity oin response to\n",
      "the given query q. Yet, there is no annotated dataset\n",
      "available for query-complexity pairs. Hence, we\n",
      "propose to automatically construct the training\n",
      "dataset with two particular strategies.\n",
      "To be specific, we first aim at labeling the query\n",
      "2We consider three levels of query complexity, and leave\n",
      "retriever vary across different multi-step retrieval-augmented\n",
      "LLM approaches (Trivedi et al., 2023; Press et al., 2023; Yao\n",
      "et al., 2023); therefore, the context cimay incorporate none,\n",
      "some, or all of the previous documents and answers.\n",
      "upon traditional BERT-like LMs. However, unlike\n",
      "our Adaptive-RAG which pre-determines the query\n",
      "complexity and adapts the operational behavior of\n",
      "any off-the-shelf LLMs accordingly, this approach\n",
      "applies the same fixed operations to every query\n",
      "regardless of its complexity but also necessitates\n",
      "additional specific training to LMs. Concurrent to\n",
      "our work, Asai et al. (2024) suggested training a so-\n",
      "phisticated model to dynamically retrieve, critique,\n",
      "The\tDivine\n",
      "Comedy\t(x) qQuery\n",
      "Encoder\n",
      "q(x)\n",
      "MIPS p θGenerator  pθ\n",
      "(Parametric)\n",
      "Margin-\n",
      "alize\n",
      "This\t14th\tcentury\twork\n",
      "is\tdivided\tinto\t3\n",
      "sections:\t\"Inferno\",\n",
      "\"Purgatorio\"\t&\n",
      "\"Paradiso\"\t\t\t\t\t\t\t\t\t (y)End-to-End Backprop through q and  p θ\n",
      "Barack\tObama\twas\n",
      "born\tin\tHawaii. (x)\n",
      "Fact V eriﬁcation: Fact Querysupports \t(y)\n",
      "Question GenerationFact V eriﬁcation:\n",
      "Label GenerationDocument\n",
      "IndexDefine\t\"middle\tear\" (x)\n",
      "Question Answering:\n",
      "Question QueryThe\tmiddle\tear\tincludes\n",
      "the\ttympanic\tcavity\tand\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 실행\n",
    "results = ensemble_retriever.invoke(\"Your query here\")\n",
    "\n",
    "# 각 결과의 page_content 출력\n",
    "for doc in results:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = load_prompt(\"02. Prompt/prompts/fruit_color.yaml\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['fruit'], template='{fruit}의 색깔이 뭐야?')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-mcYdBRZz-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
