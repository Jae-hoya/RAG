{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`mode='paged'` is deprecated in favor of the 'by_page' chunking strategy. Learn more about chunking here: https://docs.unstructured.io/open-source/core-functionality/chunking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "loader = UnstructuredPDFLoader(\"./data/asdff.pdf\", mode=\"paged\")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='다중공선성은 독립변수간 상관관계가 있는지 나타\n",
      "\n",
      "Model\n",
      "\n",
      "Accuracy\n",
      "\n",
      "내는 지표이다. 본 연구에서 사용한 데이터에서는 각 독립변수는 각 column이 된다. 만약 다중공선성이 높\n",
      "\n",
      "XGB\n",
      "\n",
      "SVC\n",
      "\n",
      "0.91\n",
      "\n",
      "0.91\n",
      "\n",
      "다면, 각 column끼리 비슷하다는 것을 의미하며, 변 수간의 차이가 없음을 의미한다. 데이터에서 column\n",
      "\n",
      "Ridge\n",
      "\n",
      "LR\n",
      "\n",
      "0.88\n",
      "\n",
      "0.89\n",
      "\n",
      "을 너무 많이 분할하면 나타나는 현상으로, 문제가 된 다면 변수를 삭제한다거나, PCA(주성분 분석) 또는 정\n",
      "\n",
      "ADA\n",
      "\n",
      "KNN\n",
      "\n",
      "0.92\n",
      "\n",
      "0.89\n",
      "\n",
      "규화를 이용해야한다. 상수항(const)은 독립변수 들이 함께 사용될 때 발생하는 자연스러운 결과이며, 독립\n",
      "\n",
      "RF\n",
      "\n",
      "DT\n",
      "\n",
      "0.89\n",
      "\n",
      "0.90\n",
      "\n",
      "변수 간의 다중공선성 문제를 반영하지않는다. 본 연 구의 데이터에선 각 각 독립변수는 데이터에서 각각의\n",
      "\n",
      "BNB\n",
      "\n",
      "GNB\n",
      "\n",
      "0.84\n",
      "\n",
      "0.85\n",
      "\n",
      "column을 의미한다. 실제로 중요한값은 독립변수의 VIF값들이다[7].\n",
      "\n",
      "DNN\n",
      "\n",
      "RNN+CNN\n",
      "\n",
      "0.88\n",
      "\n",
      "0.92\n",
      "\n",
      "Table.1 VIF(Variance Inflation Factors)\n",
      "\n",
      "위 표2는 각각 모델별 Accuracy를 보여준다. 전체적 으로 높은 정확도를 보여준다. 수식을 쉽게 표현하면\n",
      "\n",
      "VIF 33.856990 1.016757 2.415670 1.113385 1.112824 1.955416 1.339696 1.001191 1.106672 1.242843 1.216712\n",
      "\n",
      "Factor features const gender age hypertension heart_disease ever_married work_type Residence_type avg_glucose_level bmi smoking_status\n",
      "\n",
      "1.087601\n",
      "\n",
      "stroke\n",
      "\n",
      "위 표1은 VIF(분산팽창인수)을 나타낸다. 이 값은,\n",
      "\n",
      "다중공선성을 나타내는 척도다. VIF값이 5보다 크면 다중 공선성에 문제가 있어 회귀 계수에 대한 신뢰할\n",
      "\n",
      "수 없는 추정치와 해석이 발생할 수 있다. 이 값이 5 미만이면 다중공선성 문제가 크지 않다고 판단한다.\n",
      "\n",
      "위에서 언급했듯이, 상수항이 높은 VIF값은 크게 신경 쓰지 않아도 된다[8]. 수식을 쉽게 표현하면 다음과 같\n",
      "\n",
      "다음과 같다.\n",
      "\n",
      "식(3)\n",
      "\n",
      "Table.3 Recall\n",
      "\n",
      "Model\n",
      "\n",
      "Recall-weight\n",
      "\n",
      "Recall-macro\n",
      "\n",
      "ADA LR XGB RF KNN SVC BNB Ridge DT GNB DNN RNN+CNN 위 표3은 Recall값을 즉, 재현율을 보여준다. 값들 은 소수점 두 번째 자리까지 나타낸다. 질병에 관해\n",
      "\n",
      "0.74 0.77 0.74 0.84 0.75 0.73 0.74 0.75 0.70 0.79 0.87 0.91\n",
      "\n",
      "0.50 0.47 0.49 0.47 0.50 0.50 0.54 0.50 0.55 0.62 0.67 0.73\n",
      "\n",
      "다.\n",
      "\n",
      "서는 Recall을 고려한다. weight평가는 클래스의 데 이터 비율에 따라 가중치를 주어지는 방법이다.\n",
      "\n",
      "(2)\n",
      "\n",
      "식\n",
      "\n",
      "macro평가 는 클래스의 성능 지표를 동일한 비율로 평균을 내는 방법이다. 본 연구에서 사용한 데이터가\n",
      "\n",
      "4.3 Accuracy 와 Recall\n",
      "\n",
      "Table.2 Accuracy\n",
      "\n",
      "5:5 데이터가 아니기 때문에, macro평균을 제시한다. 수식은 다음과 같다.\n",
      "\n",
      "' metadata={'source': './data/asdff.pdf', 'coordinates': {'points': ((304.7999955, 644.677622375), (304.7999955, 667.477989875), (510.2958673183595, 667.477989875), (510.2958673183595, 644.677622375)), 'system': 'PixelSpace', 'layout_width': 595.32001, 'layout_height': 841.92004}, 'filename': 'asdff.pdf', 'file_directory': './data', 'last_modified': '2024-10-04T04:36:50', 'filetype': 'application/pdf', 'page_number': 5, 'links': [], 'parent_id': '9774880dfbf32b4c6c7aa3e0be8cedda'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='식(4)\n",
      "\n",
      "법이 더 좋은 성능을 가졌다. 또한, ROC-AUC에서는\n",
      "\n",
      "Table.4 ROC-AUC\n",
      "\n",
      "딥러닝 기법들이 좋은 성능을 가지는 것을 확인할\n",
      "\n",
      "Model ADA\n",
      "\n",
      "LR\n",
      "\n",
      "ROC-AUC 0.51\n",
      "\n",
      "0.5\n",
      "\n",
      "수 있다.\n",
      "\n",
      "본 연구는 비교적 작은데이터셋과 작은 모델로 각\n",
      "\n",
      "XGB\n",
      "\n",
      "0.51\n",
      "\n",
      "column의 유무별로 따져보아 뇌졸중을 판단하는데\n",
      "\n",
      "RF\n",
      "\n",
      "0.5\n",
      "\n",
      "도움을 준다. 이것은 환자의 간단한 문진표 작성을\n",
      "\n",
      "KNN\n",
      "\n",
      "0.5\n",
      "\n",
      "통해 뇌졸중에 경고와 뇌졸중 검사를 장려 할 수 있\n",
      "\n",
      "SVC\n",
      "\n",
      "0.5\n",
      "\n",
      "다. 향후 연구로 문진표를 기반으로, 추가적인 뇌졸\n",
      "\n",
      "BNB\n",
      "\n",
      "0.54\n",
      "\n",
      "중 이미지 데이터를 통해 뇌졸중 자동화 판단을 할\n",
      "\n",
      "Ridge\n",
      "\n",
      "0.5\n",
      "\n",
      "때 근거를 제시하고, 정밀검사까지 장려할 수 있다.\n",
      "\n",
      "DT\n",
      "\n",
      "0.54\n",
      "\n",
      "마지막으로, 개인적인 신상정보, 의료데이터를 가지\n",
      "\n",
      "GNB\n",
      "\n",
      "0.62\n",
      "\n",
      "고 실험을 하기 때문에, 항상 윤리적인 사항에 유념\n",
      "\n",
      "DNN RNN+CNN\n",
      "\n",
      "0.81 0.83\n",
      "\n",
      "을 가지고 데이터를 구성해야한다. 추후에 윤리적,\n",
      "\n",
      "위 표4는 ROC-AUC값을 보여준다. 데이터가 불균 형하기 때문에, 그림.6 Distribution Stroke 그림에서\n",
      "\n",
      "신상정보를 고려한 더 많은 데이터를 가진다면 더\n",
      "\n",
      "높은 성능과 알고리즘을 고려할 수 있을 것이다.\n",
      "\n",
      "불균형 데이터 이기 때문에 ROC-AUC평가방법은 의 미가 있다[9]. 딥러닝 모델의 결과값이 현저하게 좋\n",
      "\n",
      "음을 보여준다. 보통 0.8이 넘으면, 모델의 점수는 높다고 평가한다.[10] 수식을 쉽게 표현하면 다음과\n",
      "\n",
      "REFERENCES [1]\n",
      "\n",
      "“Stroke”, Korea association of health promotion, vol.31,\n",
      "\n",
      "issue\n",
      "\n",
      "1,\n",
      "\n",
      "pp.\n",
      "\n",
      "30-31,\n",
      "\n",
      "2007\n",
      "\n",
      "같다.\n",
      "\n",
      "[Internet].Available:https://www.koreascience.or.kr/article/J\n",
      "\n",
      "AKO200762680456596.page\n",
      "\n",
      "식(5)\n",
      "\n",
      "[2] WHO and FAO announce global\n",
      "\n",
      "initiative to promote\n",
      "\n",
      "consumption\n",
      "\n",
      "of\n",
      "\n",
      "fruit\n",
      "\n",
      "and vegetables, World Health\n",
      "\n",
      "Organization ,\n",
      "\n",
      "2003.\n",
      "\n",
      "Ⅴ. 결론 및 향후연구\n",
      "\n",
      "[Internet].Available: https://www.who.int/news/item/11-11-2\n",
      "\n",
      "003-who-and-fao-announce-global-initiative-to-promote-con\n",
      "\n",
      "본 연구는 Kaggle 의 stroke data를 가지고와 뇌졸\n",
      "\n",
      "sumption-of-fruit-and-vegetables.\n",
      "\n",
      "[3] Kaggle Data\n",
      "\n",
      "set, Stroke Prediction Dataset,\n",
      "\n",
      "2021.\n",
      "\n",
      "중 데이터를 통해서 머신러닝 분류기법과 딥러닝의\n",
      "\n",
      "[Internet].Available: https://www.kaggle.com/datasets/fedeso\n",
      "\n",
      "DNN, CNN+RNN의 앙상블 기법을 통해 뇌졸중을\n",
      "\n",
      "riano/stroke-prediction-dataset .\n",
      "\n",
      "판단한다. 텍스트처리, 자연어처리, 시퀀스 데이터,\n",
      "\n",
      "[4] S. Chen, G. I. Webb, L. Liu, X. Ma, “A novel selective naïve\n",
      "\n",
      "시계열 데이터에 자주쓰이는 RNN과 이미지 특징추\n",
      "\n",
      "Bayes algorithm”, Knowledge-Based Systems, vol.192, Mar,\n",
      "\n",
      "2020. DOI: https://doi.org/10.1016/j.knosys.2019.105361\n",
      "\n",
      "출에 자주 쓰이고, 가끔은 텍스트 처리에 사용되는\n",
      "\n",
      "[5] R. Hataya, J. Zdenek, K. Yoshizoe, H Nakayama, “Faster\n",
      "\n",
      "CNN을 앙상블 하여 이용한다. RNN과 CNN을 앙상\n",
      "\n",
      "AutoAugment: Learning Augmentation Strategies using\n",
      "\n",
      "블 하여 질병 데이터를 가지고 이진분류를 수행하면,\n",
      "\n",
      "Backpropagation ”, Computer Vision-ECCV 2020: 16th\n",
      "\n",
      "다양한 데이터 특성을 효과적으로 학습하고, 더 나은\n",
      "\n",
      "일반화 성능과 예측 정확도를 얻을 수 있다. 이는 특\n",
      "\n",
      "European Conference , Glasgow:USA, pp. 1-16, Aug, 2020.\n",
      "\n",
      "DOI: https://doi.org/10.1007/978-3-030-58595-2_1\n",
      "\n",
      "[6] A. Mahdaddi, S. Meshoul, M. Belguidoum, \"EA-based\n",
      "\n",
      "히 복잡하고 다양한 형태의 의료 데이터를 처리하는\n",
      "\n",
      "hyperparameter optimization of hybrid deep learning models\n",
      "\n",
      "데 매우 유용하다. 그에 대한 평가 방법으로는 Accur\n",
      "\n",
      "for effective drug-target\n",
      "\n",
      "interactions prediction,\" Expert\n",
      "\n",
      "acy와 Recall을 사용했고, Accuracy 방면에서는 모두\n",
      "\n",
      "좋은 결과값을 가졌지만 Recall방면에서는 앙상블 기\n",
      "\n",
      "Systems with Applications,\n",
      "\n",
      "vol.185, Dec,\n",
      "\n",
      "DOI:doi.org/10.1016/j.eswa.2021.115525.\n",
      "\n",
      "2021.\n",
      "\n",
      "' metadata={'source': './data/asdff.pdf', 'coordinates': {'points': ((492.4546603202586, 676.35049355), (492.4546603202586, 684.27079355), (509.8001173202586, 684.27079355), (509.8001173202586, 676.35049355)), 'system': 'PixelSpace', 'layout_width': 595.32001, 'layout_height': 841.92004}, 'filename': 'asdff.pdf', 'file_directory': './data', 'last_modified': '2024-10-04T04:36:50', 'filetype': 'application/pdf', 'parent_id': '01f3d4a0394a4fda67993ed15a4e5d22', 'page_number': 6, 'links': []}\n"
     ]
    }
   ],
   "source": [
    "print(docs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=50\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected metadata value to be a str, int, float or bool, got {'points': ((118.5600015, 727.0558084700001), (118.5600015, 733.05604097), (280.3577943515331, 733.05604097), (280.3577943515331, 727.0558084700001)), 'system': 'PixelSpace', 'layout_width': 595.32001, 'layout_height': 841.92004} which is a <class 'dict'>\n\nTry filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:299\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:477\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \n\u001b[0;32m    460\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m (\n\u001b[0;32m    471\u001b[0m     ids,\n\u001b[0;32m    472\u001b[0m     embeddings,\n\u001b[0;32m    473\u001b[0m     metadatas,\n\u001b[0;32m    474\u001b[0m     documents,\n\u001b[0;32m    475\u001b[0m     images,\n\u001b[0;32m    476\u001b[0m     uris,\n\u001b[1;32m--> 477\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muris\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:554\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[1;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001b[0m\n\u001b[0;32m    546\u001b[0m valid_embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    547\u001b[0m     validate_embeddings(\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    552\u001b[0m )\n\u001b[0;32m    553\u001b[0m valid_metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 554\u001b[0m     \u001b[43mvalidate_metadatas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_cast_one_to_many_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    557\u001b[0m )\n\u001b[0;32m    558\u001b[0m valid_documents \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    559\u001b[0m     maybe_cast_one_to_many_document(documents)\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    562\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\chromadb\\api\\types.py:310\u001b[0m, in \u001b[0;36mvalidate_metadatas\u001b[1;34m(metadatas)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m metadatas:\n\u001b[1;32m--> 310\u001b[0m     \u001b[43mvalidate_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadatas\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\chromadb\\api\\types.py:278\u001b[0m, in \u001b[0;36mvalidate_metadata\u001b[1;34m(metadata)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[1;32m--> 278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be a str, int, float or bool, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         )\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[1;31mValueError\u001b[0m: Expected metadata value to be a str, int, float or bool, got {'points': ((118.5600015, 727.0558084700001), (118.5600015, 733.05604097), (280.3577943515331, 733.05604097), (280.3577943515331, 727.0558084700001)), 'system': 'PixelSpace', 'layout_width': 595.32001, 'layout_height': 841.92004} which is a <class 'dict'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      4\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:878\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    876\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    877\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:836\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    831\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    832\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    833\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    834\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    835\u001b[0m     ):\n\u001b[1;32m--> 836\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    842\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32mc:\\Users\\skyop\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-gLkynrUQ-py3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:311\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[0;32m    307\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry filtering complex metadata from the document using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_community.vectorstores.utils.filter_complex_metadata.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mValueError\u001b[0m: Expected metadata value to be a str, int, float or bool, got {'points': ((118.5600015, 727.0558084700001), (118.5600015, 733.05604097), (280.3577943515331, 733.05604097), (280.3577943515331, 727.0558084700001)), 'system': 'PixelSpace', 'layout_width': 595.32001, 'layout_height': 841.92004} which is a <class 'dict'>\n\nTry filtering complex metadata from the document using langchain_community.vectorstores.utils.filter_complex_metadata."
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vector_store = Chroma.from_documents(documents, embeddings)\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 4, 'source': './data/asdff.pdf'}, page_content='서는 Recall을 고려한다. weight평가는 클래스의 데\\n이터 비율에 따라 가중치를 주어지는 방법이다.\\nmacro평가 는 클래스의 성능 지표를 동일한 비율로\\n평균을 내는 방법이다. 본 연구에서 사용한 데이터가\\n5:5 데이터가 아니기 때문에, macro평균을 제시한다.\\n수식은 다음과 같다.\\nVIF Factor features\\n33.856990 const\\n1.016757 gender\\n2.415670 age\\n1.113385 hypertension\\n1.112824 heart_disease\\n1.955416 ever_married\\n1.339696 work_type\\n1.001191 Residence_type\\n1.106672 avg_glucose_level\\n1.242843 bmi\\n1.216712 smoking_status\\n1.087601 strokeModel Recall-weight Recall-macro\\nADA 0.74 0.50\\nLR 0.77 0.47\\nXGB 0.74 0.49\\nRF 0.84 0.47\\nKNN 0.75 0.50\\nSVC 0.73 0.50\\nBNB 0.74 0.54\\nRidge 0.75 0.50\\nDT 0.70 0.55\\nGNB 0.79 0.62\\nDNN 0.87 0.67\\nRNN+CNN 0.91 0.735'),\n",
       " Document(metadata={'page': 4, 'source': './data/asdff.pdf'}, page_content='Table.3 Recall\\n위 표3은 Recall값을 즉, 재현율을 보여준다. 값들\\n은 소수점 두 번째 자리까지 나타낸다. 질병에 관해\\n서는 Recall을 고려한다. weight평가는 클래스의 데\\n이터 비율에 따라 가중치를 주어지는 방법이다.\\nmacro평가 는 클래스의 성능 지표를 동일한 비율로\\n평균을 내는 방법이다. 본 연구에서 사용한 데이터가\\n5:5 데이터가 아니기 때문에, macro평균을 제시한다.\\n수식은 다음과 같다.\\nVIF Factor features\\n33.856990 const\\n1.016757 gender\\n2.415670 age\\n1.113385 hypertension\\n1.112824 heart_disease\\n1.955416 ever_married\\n1.339696 work_type\\n1.001191 Residence_type\\n1.106672 avg_glucose_level\\n1.242843 bmi\\n1.216712 smoking_status'),\n",
       " Document(metadata={'page': 4, 'source': './data/asdff.pdf'}, page_content='다중공선성을 나타내는 척도다. VIF값이 5보다 크면\\n다중 공선성에 문제가 있어 회귀 계수에 대한 신뢰할\\n수 없는 추정치와 해석이 발생할 수 있다. 이 값이 5\\n미만이면 다중공선성 문제가 크지 않다고 판단한다.\\n위에서 언급했듯이, 상수항이 높은 VIF값은 크게 신경\\n쓰지 않아도 된다[8]. 수식을 쉽게 표현하면 다음과 같\\n다.\\n식\\n(2)\\n4.3 Accuracy와 Recall\\nTable.2 AccuracyModel Accuracy\\nXGB 0.91\\nSVC 0.91\\nRidge 0.88\\nLR 0.89\\nADA 0.92\\nKNN 0.89\\nRF 0.89\\nDT 0.90\\nBNB 0.84\\nGNB 0.85\\nDNN 0.88\\nRNN+CNN 0.92\\n위 표2는 각각 모델별 Accuracy를 보여준다. 전체적\\n으로 높은 정확도를 보여준다. 수식을 쉽게 표현하면\\n다음과 같다.\\n식(3)\\nTable.3 Recall\\n위 표3은 Recall값을 즉, 재현율을 보여준다. 값들'),\n",
       " Document(metadata={'page': 4, 'source': './data/asdff.pdf'}, page_content='다중공선성은 독립변수간 상관관계가 있는지 나타\\n내는 지표이다. 본 연구에서 사용한 데이터에서는 각\\n독립변수는 각 column이 된다. 만약 다중공선성이 높\\n다면, 각 column끼리 비슷하다는 것을 의미하며, 변\\n수간의 차이가 없음을 의미한다. 데이터에서 column\\n을 너무 많이 분할하면 나타나는 현상으로, 문제가 된\\n다면 변수를 삭제한다거나, PCA(주성분 분석) 또는 정\\n규화를 이용해야한다. 상수항(const)은 독립변수 들이\\n함께 사용될 때 발생하는 자연스러운 결과이며, 독립\\n변수 간의 다중공선성 문제를 반영하지않는다. 본 연\\n구의 데이터에선 각 각 독립변수는 데이터에서 각각의\\ncolumn을 의미한다. 실제로 중요한값은 독립변수의\\nVIF값들이다[7].\\nTable.1 VIF(Variance Inflation Factors)\\n위 표1은 VIF(분산팽창인수)을 나타낸다. 이 값은,\\n다중공선성을 나타내는 척도다. VIF값이 5보다 크면\\n다중 공선성에 문제가 있어 회귀 계수에 대한 신뢰할\\n수 없는 추정치와 해석이 발생할 수 있다. 이 값이 5\\n미만이면 다중공선성 문제가 크지 않다고 판단한다.\\n위에서 언급했듯이, 상수항이 높은 VIF값은 크게 신경\\n쓰지 않아도 된다[8]. 수식을 쉽게 표현하면 다음과 같\\n다.\\n식\\n(2)\\n4.3 Accuracy와 Recall\\nTable.2 AccuracyModel Accuracy\\nXGB 0.91\\nSVC 0.91\\nRidge 0.88\\nLR 0.89\\nADA 0.92\\nKNN 0.89\\nRF 0.89\\nDT 0.90\\nBNB 0.84\\nGNB 0.85\\nDNN 0.88\\nRNN+CNN 0.92\\n위 표2는 각각 모델별 Accuracy를 보여준다. 전체적\\n으로 높은 정확도를 보여준다. 수식을 쉽게 표현하면\\n다음과 같다.\\n식(3)\\nTable.3 Recall\\n위 표3은 Recall값을 즉, 재현율을 보여준다. 값들\\n은 소수점 두 번째 자리까지 나타낸다. 질병에 관해\\n서는 Recall을 고려한다. weight평가는 클래스의 데')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"본 논문에서 각각 알고리즘마다 recall값 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Please write your answer in a markdown table format with the main points.\n",
    "    Be sure to include your source and page numbers in your answer.\n",
    "    Answer in Korean.\n",
    "\n",
    "    #Example Format:\n",
    "    (brief summary of the answer)\n",
    "    (table)\n",
    "    (detailed answer to the question)\n",
    "\n",
    "    **출처**\n",
    "    - (page source and page number)\n",
    "\n",
    "    #Question: \n",
    "    {question}\n",
    "\n",
    "    #Context: \n",
    "    {context} \n",
    "\n",
    "    #Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "         | prompt\n",
    "         | llm\n",
    "         | StrOutputParser()\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "response= chain.invoke(\"본 논문에서 각각 알고리즘마다 recall값 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 모델의 Recall 값은 다음과 같습니다.\n",
      "\n",
      "| 모델        | Recall-weight | Recall-macro |\n",
      "|-------------|---------------|---------------|\n",
      "| ADA         | 0.74          | 0.50          |\n",
      "| LR          | 0.77          | 0.47          |\n",
      "| XGB         | 0.74          | 0.49          |\n",
      "| RF          | 0.84          | 0.47          |\n",
      "| KNN         | 0.75          | 0.50          |\n",
      "| SVC         | 0.73          | 0.50          |\n",
      "| BNB         | 0.74          | 0.54          |\n",
      "| Ridge       | 0.75          | 0.50          |\n",
      "| DT          | 0.70          | 0.55          |\n",
      "| GNB         | 0.79          | 0.62          |\n",
      "| DNN         | 0.87          | 0.67          |\n",
      "| RNN+CNN     | 0.91          | 0.735         |\n",
      "\n",
      "**출처**\n",
      "- ./data/asdff.pdf, 페이지 4\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = chain.invoke(\"본 논문에서 제시하는 알고리즘마다 vif값 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본 논문에서는 다양한 알고리즘에 대한 VIF 값을 직접적으로 언급하고 있지 않으며, VIF(분산팽창인수)에 대한 일반적인 설명만 포함되어 있습니다. VIF 값이 5보다 크면 다중 공선성에 문제가 있을 수 있음을 강조하고 있습니다.\n",
      "\n",
      "| 요점                           | 내용                                          |\n",
      "|--------------------------------|-----------------------------------------------|\n",
      "| VIF의 정의                     | 다중공선성을 나타내는 척도                   |\n",
      "| VIF 값 기준                    | 5보다 크면 다중 공선성 문제 가능성 있음     |\n",
      "| 상수항 VIF 값                  | 높을 경우 크게 신경 쓰지 않아도 됨          |\n",
      "\n",
      "자세한 내용으로, 본 연구에서는 각 독립변수의 VIF 값이 중요하다고 언급하며, 다중공선성이 높을 경우 변수 삭제, PCA 또는 정규화 방법을 통해 해결할 수 있다고 설명합니다. 그러나 구체적인 알고리즘별 VIF 값은 제공되지 않습니다.\n",
      "\n",
      "**출처**\n",
      "- ./data/asdff.pdf (페이지 4)\n"
     ]
    }
   ],
   "source": [
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = chain.invoke(\"본 논문에서 제시하는 변수마다 accuracy값 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다중공선성과 모델별 정확도(accuracy)에 대한 정보가 포함된 문서에서, 각 모델의 accuracy 값은 다음과 같습니다.\n",
      "\n",
      "| 모델      | 정확도 (Accuracy) |\n",
      "|-----------|--------------------|\n",
      "| XGB       | 0.91               |\n",
      "| SVC       | 0.91               |\n",
      "| Ridge     | 0.88               |\n",
      "| LR        | 0.89               |\n",
      "| ADA       | 0.92               |\n",
      "| KNN       | 0.89               |\n",
      "| RF        | 0.89               |\n",
      "| DT        | 0.90               |\n",
      "| BNB       | 0.84               |\n",
      "| GNB       | 0.85               |\n",
      "| DNN       | 0.88               |\n",
      "| RNN+CNN   | 0.92               |\n",
      "\n",
      "**출처**\n",
      "- ./data/asdff.pdf, 페이지 4\n"
     ]
    }
   ],
   "source": [
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response4 = chain.invoke(\"\")\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-gLkynrUQ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
